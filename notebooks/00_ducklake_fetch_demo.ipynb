{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc047b9",
   "metadata": {},
   "source": [
    "# Demoing fetching PV locations from DuckLake into a LanceDB dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419c6b6",
   "metadata": {},
   "source": [
    "### References:\n",
    "- [DuckLake Documentation](https://ducklake.select/docs/stable/)\n",
    "- [DuckLake with Ibis Python DataFrames](https://emilsadek.com/blog/ducklake-ibis/)\n",
    "- [A new data lakehouse with DuckLake and dbt](https://giacomo.coletto.io/blog/ducklake/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776bafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "from ibis import _\n",
    "import ibis.selectors as s\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from huggingface_hub import HfFileSystem, login\n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely import wkt\n",
    "import s2cell\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c79ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DuckLake catalog type: postgres\n",
      "  DATA_PATH: 's3://eo-pv-lakehouse/ducklake_data'\n"
     ]
    }
   ],
   "source": [
    "ibis.options.interactive = True\n",
    "ibis.options.graphviz_repr=True\n",
    "random.seed(24765131)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# assume we're using prod catalog, but default to local/dev if env var not set\n",
    "local_default = os.getenv('DUCKLAKE_CONNECTION_STRING_DEV')\n",
    "DUCKLAKE_CATALOG = os.getenv('DUCKLAKE_CONNECTION_STRING_PROD', local_default)\n",
    "DUCKLAKE_ATTACH = os.getenv(\"DUCKLAKE_ATTACH_PROD\")\n",
    "DUCKLAKE_NAME = os.getenv(\"DUCKLAKE_NAME\")\n",
    "DUCKLAKE_DATA_PATH = os.getenv(\"DUCKLAKE_DATA_PATH\")\n",
    "\n",
    "# pretty print our connection string info \n",
    "# TODO: comment out and remove output before commit\n",
    "print(f\"Using DuckLake catalog type: {DUCKLAKE_CATALOG.split(':')[1]}\" )\n",
    "catalog_creds = DUCKLAKE_CATALOG.split(':')[2].strip('()').split(' ')\n",
    "# skip DATA_PATH at end\n",
    "for cred in catalog_creds[:-2]:\n",
    "    key, val = cred.split('=')\n",
    "    # print(f\"  {key}: {val}\")\n",
    "print(f\"  DATA_PATH: {DUCKLAKE_CATALOG.split('DATA_PATH ')[1][:-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563012e9",
   "metadata": {},
   "source": [
    "### Connect to our data lake catalog with ibis \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bea8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f714ad10ae049f1be742bf97d2ef257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae50c18178840d78edb2403f5fefbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ec59f7724a40b087be9af38c2a614c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96743355f90a400dba1a30fae97e2462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "duckdb_config = {\n",
    "    'threads': 6,\n",
    "    'memory_limit': '12GB',\n",
    "    's3_access_key_id': os.getenv('R2_ACCESS_KEY_ID'),\n",
    "    's3_secret_access_key': os.getenv('R2_SECRET_KEY'),\n",
    "    's3_endpoint': os.getenv('R2_S3_ENDPOINT'),\n",
    "    's3_use_ssl': 'true',\n",
    "    's3_url_style': 'path'\n",
    "}\n",
    "\n",
    "# use in-memory/ephemeral db\n",
    "con = ibis.duckdb.connect(\n",
    "    extensions=[\"ducklake\", \"spatial\", \"h3\", \"httpfs\"],\n",
    "    **duckdb_config\n",
    "    )\n",
    "\n",
    "# r2_bucket_setup = f\"\"\"SET s3_access_key_id='{os.getenv('R2_ACCESS_KEY_ID')}';\n",
    "# SET s3_secret_access_key='{os.getenv('R2_SECRET_KEY')}';\n",
    "# SET s3_endpoint='{os.getenv('R2_S3_ENDPOINT')}';\n",
    "# SET s3_use_ssl='true';\n",
    "# SET s3_url_style='path';\n",
    "# \"\"\"\n",
    "# con.raw_sql(r2_bucket_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578360db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__ducklake_metadata_eo_pv_lakehouse',\n",
       " 'eo_pv_lakehouse',\n",
       " 'memory',\n",
       " 'system',\n",
       " 'temp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# con.load_extension(\"ducklake\")\n",
    "attach_catalog_sql = f\"\"\"ATTACH IF NOT EXISTS '{DUCKLAKE_ATTACH}' AS {DUCKLAKE_NAME}\n",
    "    (DATA_PATH '{DUCKLAKE_DATA_PATH}');\n",
    "USE {DUCKLAKE_NAME};\n",
    "\"\"\"\n",
    "con.raw_sql(attach_catalog_sql)\n",
    "# add community cache_httpfs extension; this causes an \"http_init already loaded\" error only when loading as part of ibis extensions arg\n",
    "# fails in Windows; commented out by default\n",
    "# con.raw_sql(\"INSTALL cache_httpfs FROM community; LOAD cache_httpfs;\")\n",
    "con.list_catalogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213ac6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c57a0bffe14eaa8078557289b13af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ede381b09b4e9bb23aae306a32e1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'pyarrow.lib.RecordBatchReader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\IPython\\core\\formatters.py:770\u001b[39m, in \u001b[36mPlainTextFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    763\u001b[39m stream = StringIO()\n\u001b[32m    764\u001b[39m printer = pretty.RepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_width, \u001b[38;5;28mself\u001b[39m.newline,\n\u001b[32m    766\u001b[39m     max_seq_length=\u001b[38;5;28mself\u001b[39m.max_seq_length,\n\u001b[32m    767\u001b[39m     singleton_pprinters=\u001b[38;5;28mself\u001b[39m.singleton_printers,\n\u001b[32m    768\u001b[39m     type_pprinters=\u001b[38;5;28mself\u001b[39m.type_printers,\n\u001b[32m    769\u001b[39m     deferred_pprinters=\u001b[38;5;28mself\u001b[39m.deferred_printers)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[43mprinter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m printer.flush()\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream.getvalue()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\IPython\\lib\\pretty.py:411\u001b[39m, in \u001b[36mRepresentationPrinter.pretty\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    401\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    402\u001b[39m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    403\u001b[39m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    409\u001b[39m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__repr__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    410\u001b[39m                 ):\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\IPython\\lib\\pretty.py:786\u001b[39m, in \u001b[36m_repr_pprint\u001b[39m\u001b[34m(obj, p, cycle)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m output = \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m lines = output.splitlines()\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m p.group():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\core.py:55\u001b[39m, in \u001b[36mExpr.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ibis.options.interactive:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcapture_rich_renderable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._noninteractive_repr()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\rich.py:48\u001b[39m, in \u001b[36mcapture_rich_renderable\u001b[39m\u001b[34m(renderable)\u001b[39m\n\u001b[32m     46\u001b[39m console = Console(force_terminal=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _with_rich_display_disabled(), console.capture() \u001b[38;5;28;01mas\u001b[39;00m capture:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[43mconsole\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m capture.get().rstrip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\rich\\console.py:1724\u001b[39m, in \u001b[36mConsole.print\u001b[39m\u001b[34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[39m\n\u001b[32m   1722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m style \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1723\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m renderable \u001b[38;5;129;01min\u001b[39;00m renderables:\n\u001b[32m-> \u001b[39m\u001b[32m1724\u001b[39m         \u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1726\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m renderable \u001b[38;5;129;01min\u001b[39;00m renderables:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\rich\\console.py:1325\u001b[39m, in \u001b[36mConsole.render\u001b[39m\u001b[34m(self, renderable, options)\u001b[39m\n\u001b[32m   1323\u001b[39m renderable = rich_cast(renderable)\n\u001b[32m   1324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(renderable, \u001b[33m\"\u001b[39m\u001b[33m__rich_console__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isclass(renderable):\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     render_iterable = \u001b[43mrenderable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__rich_console__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(renderable, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1327\u001b[39m     text_renderable = \u001b[38;5;28mself\u001b[39m.render_str(\n\u001b[32m   1328\u001b[39m         renderable, highlight=_options.highlight, markup=_options.markup\n\u001b[32m   1329\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\core.py:76\u001b[39m, in \u001b[36mExpr.__rich_console__\u001b[39m\u001b[34m(self, console, options)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m opts.interactive:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         rich_object = \u001b[43mto_rich\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsole_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsole_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     78\u001b[39m         rich_object = Text(\u001b[38;5;28mself\u001b[39m._noninteractive_repr())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\rich.py:70\u001b[39m, in \u001b[36mto_rich\u001b[39m\u001b[34m(expr, max_rows, max_columns, max_length, max_string, max_depth, console_width)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m to_rich_scalar(\n\u001b[32m     67\u001b[39m         expr, max_length=max_length, max_string=max_string, max_depth=max_depth\n\u001b[32m     68\u001b[39m     )\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_rich_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconsole_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsole_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\_rich.py:341\u001b[39m, in \u001b[36mto_rich_table\u001b[39m\u001b[34m(tablish, max_rows, max_columns, max_length, max_string, max_depth, console_width)\u001b[39m\n\u001b[32m    337\u001b[39m remaining = console_width - \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# 1 char for left boundary\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, dtype \u001b[38;5;129;01min\u001b[39;00m table.schema().items():\n\u001b[32m    339\u001b[39m     formatted, min_width, max_width = format_column(\n\u001b[32m    340\u001b[39m         dtype,\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m         \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m.to_pylist()[:max_rows],\n\u001b[32m    342\u001b[39m         max_length=max_length,\n\u001b[32m    343\u001b[39m         max_string=max_string,\n\u001b[32m    344\u001b[39m         max_depth=max_depth,\n\u001b[32m    345\u001b[39m     )\n\u001b[32m    346\u001b[39m     dtype_str = format_dtype(dtype, max_string)\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m show_types \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, (dt.Struct, dt.Map, dt.Array)):\n\u001b[32m    348\u001b[39m         \u001b[38;5;66;03m# Don't truncate non-nested dtypes\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'pyarrow.lib.RecordBatchReader' object is not subscriptable"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:76\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = subprocess.PIPE\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     proc = \u001b[43m_run_input_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:96\u001b[39m, in \u001b[36m_run_input_lines\u001b[39m\u001b[34m(cmd, input_lines, kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_input_lines\u001b[39m(cmd, input_lines, *, kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     popen = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     stdin_write = popen.stdin.write\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\subprocess.py:1538\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1540\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1547\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1548\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1551\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mExecutableNotFound\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m h3_test = stg_pv.sample(\u001b[32m0.01\u001b[39m).select(\u001b[33m\"\u001b[39m\u001b[33munified_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcentroid_lat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcentroid_lon\u001b[39m\u001b[33m\"\u001b[39m).\\\n\u001b[32m     12\u001b[39m     mutate(h3_cell=h3_latlng_to_cell_string(_.centroid_lat, _.centroid_lon, \u001b[32m8\u001b[39m)).head(\u001b[32m10\u001b[39m)\n\u001b[32m     13\u001b[39m display(h3_test)\n\u001b[32m     14\u001b[39m \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstg_pv_consolidated\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munified_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcentroid_lat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcentroid_lon\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmutate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh3_cell\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh3_latlng_to_cell_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcentroid_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcentroid_lon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpng\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\core.py:219\u001b[39m, in \u001b[36mExpr.visualize\u001b[39m\u001b[34m(self, format, label_edges, verbose, node_attr, node_attr_getter, edge_attr, edge_attr_getter)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Visualize an expression as a GraphViz graph in the browser.\u001b[39;00m\n\u001b[32m    171\u001b[39m \n\u001b[32m    172\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    215\u001b[39m \u001b[33;03m    If `graphviz` is not installed.\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mibis\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpr\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mviz\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m path = \u001b[43mviz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mviz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_attr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_attr_getter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_attr_getter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_attr_getter\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_attr_getter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_edges\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_edges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m webbrowser.open(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.abspath(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\visualize.py:173\u001b[39m, in \u001b[36mdraw\u001b[39m\u001b[34m(graph, path, format, verbose)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28mprint\u001b[39m(graph.source, file=sys.stderr)  \u001b[38;5;66;03m# noqa: T201\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m piped_source = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tempfile.NamedTemporaryFile(\n\u001b[32m    177\u001b[39m         delete=\u001b[38;5;28;01mFalse\u001b[39;00m, suffix=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\graphviz\\piping.py:104\u001b[39m, in \u001b[36mPipe.pipe\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpipe\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m     56\u001b[39m          \u001b[38;5;28mformat\u001b[39m: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     57\u001b[39m          renderer: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m          engine: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     62\u001b[39m          encoding: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> typing.Union[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m \u001b[33;03m        '<?xml version='\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_legacy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\graphviz\\_tools.py:185\u001b[39m, in \u001b[36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     wanted = \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    178\u001b[39m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated.items())\n\u001b[32m    179\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m will be reduced\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    180\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m positional arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mqualification\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as keyword arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m    182\u001b[39m                   stacklevel=stacklevel,\n\u001b[32m    183\u001b[39m                   category=category)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\graphviz\\piping.py:121\u001b[39m, in \u001b[36mPipe._pipe_legacy\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@_tools\u001b[39m.deprecate_positional_args(supported_number=\u001b[32m1\u001b[39m, ignore_arg=\u001b[33m'\u001b[39m\u001b[33mself\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pipe_legacy\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    114\u001b[39m                  \u001b[38;5;28mformat\u001b[39m: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m                  engine: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    120\u001b[39m                  encoding: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> typing.Union[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\graphviz\\piping.py:161\u001b[39m, in \u001b[36mPipe._pipe_future\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m raw.decode(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_encoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\graphviz\\backend\\piping.py:161\u001b[39m, in \u001b[36mpipe_lines\u001b[39m\u001b[34m(engine, format, input_lines, input_encoding, renderer, formatter, neato_no_op, quiet)\u001b[39m\n\u001b[32m    155\u001b[39m cmd = dot_command.command(engine, \u001b[38;5;28mformat\u001b[39m,\n\u001b[32m    156\u001b[39m                           renderer=renderer,\n\u001b[32m    157\u001b[39m                           formatter=formatter,\n\u001b[32m    158\u001b[39m                           neato_no_op=neato_no_op)\n\u001b[32m    159\u001b[39m kwargs = {\u001b[33m'\u001b[39m\u001b[33minput_lines\u001b[39m\u001b[33m'\u001b[39m: (line.encode(input_encoding) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m input_lines)}\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m proc = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proc.stdout\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno == errno.ENOENT:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc.stderr:\n",
      "\u001b[31mExecutableNotFound\u001b[39m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "from ibis import _ \n",
    "\n",
    "# ibis loading of extensions fails in colab and Windows\n",
    "con.raw_sql(\"INSTALL h3 FROM community; LOAD h3;\")\n",
    "# test h3 functionality: https://github.com/isaacbrodsky/h3-duckdb?tab=readme-ov-file#full-list-of-functions\n",
    "@ibis.udf.scalar.builtin\n",
    "def h3_latlng_to_cell_string(lat: float, lng: float, resolution: int) -> str:\n",
    "    '''Convert latitude/longitude coordinate to cell ID'''\n",
    "\n",
    "# and ibis udf that enables using backend's (duckdb) functions including extensions: https://ibis-project.org/reference/scalar-udfs#ibis.expr.operations.udf.scalar.builtin\n",
    "h3_test = stg_pv.sample(0.01).select(\"unified_id\", \"centroid_lat\", \"centroid_lon\").\\\n",
    "    mutate(h3_cell=h3_latlng_to_cell_string(_.centroid_lat, _.centroid_lon, 8)).head(10)\n",
    "display(h3_test)\n",
    "con.table(\"stg_pv_consolidated\").sample(0.01).select(\"unified_id\", \"centroid_lat\", \"centroid_lon\").\\\n",
    "    mutate(h3_cell=h3_latlng_to_cell_string(_.centroid_lat, _.centroid_lon, 8)).head(10).visualize(format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93bad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9497ec1997b441995e4ce3574619fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['pv_h3_cells',\n",
       " 'pv_h3_grid',\n",
       " 'raw_chn_med_res_pv_2024',\n",
       " 'raw_global_harmonized_large_solar_farms_2020',\n",
       " 'raw_global_pv_inventory_sent2_spot_2021',\n",
       " 'raw_ind_pv_solar_farms_2022',\n",
       " 'raw_uk_crowdsourced_pv_2020',\n",
       " 'raw_usa_cali_usgs_pv_2016',\n",
       " 'stg_chn_med_res_pv_2024',\n",
       " 'stg_global_harmonized_large_solar_farms_2020',\n",
       " 'stg_global_pv_inventory_sent2_spot_2021',\n",
       " 'stg_ind_pv_solar_farms_2022',\n",
       " 'stg_pv_consolidated',\n",
       " 'stg_uk_crowdsourced_pv_2020',\n",
       " 'stg_usa_cali_usgs_pv_2016']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7663a706",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'pyarrow.lib.RecordBatchReader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\IPython\\core\\formatters.py:770\u001b[39m, in \u001b[36mPlainTextFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    763\u001b[39m stream = StringIO()\n\u001b[32m    764\u001b[39m printer = pretty.RepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_width, \u001b[38;5;28mself\u001b[39m.newline,\n\u001b[32m    766\u001b[39m     max_seq_length=\u001b[38;5;28mself\u001b[39m.max_seq_length,\n\u001b[32m    767\u001b[39m     singleton_pprinters=\u001b[38;5;28mself\u001b[39m.singleton_printers,\n\u001b[32m    768\u001b[39m     type_pprinters=\u001b[38;5;28mself\u001b[39m.type_printers,\n\u001b[32m    769\u001b[39m     deferred_pprinters=\u001b[38;5;28mself\u001b[39m.deferred_printers)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[43mprinter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m printer.flush()\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream.getvalue()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\IPython\\lib\\pretty.py:411\u001b[39m, in \u001b[36mRepresentationPrinter.pretty\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    401\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    402\u001b[39m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    403\u001b[39m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    409\u001b[39m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__repr__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    410\u001b[39m                 ):\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\IPython\\lib\\pretty.py:786\u001b[39m, in \u001b[36m_repr_pprint\u001b[39m\u001b[34m(obj, p, cycle)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m output = \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m lines = output.splitlines()\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m p.group():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\core.py:55\u001b[39m, in \u001b[36mExpr.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ibis.options.interactive:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcapture_rich_renderable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._noninteractive_repr()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\rich.py:48\u001b[39m, in \u001b[36mcapture_rich_renderable\u001b[39m\u001b[34m(renderable)\u001b[39m\n\u001b[32m     46\u001b[39m console = Console(force_terminal=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _with_rich_display_disabled(), console.capture() \u001b[38;5;28;01mas\u001b[39;00m capture:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[43mconsole\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m capture.get().rstrip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\rich\\console.py:1724\u001b[39m, in \u001b[36mConsole.print\u001b[39m\u001b[34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[39m\n\u001b[32m   1722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m style \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1723\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m renderable \u001b[38;5;129;01min\u001b[39;00m renderables:\n\u001b[32m-> \u001b[39m\u001b[32m1724\u001b[39m         \u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1726\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m renderable \u001b[38;5;129;01min\u001b[39;00m renderables:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\rich\\console.py:1325\u001b[39m, in \u001b[36mConsole.render\u001b[39m\u001b[34m(self, renderable, options)\u001b[39m\n\u001b[32m   1323\u001b[39m renderable = rich_cast(renderable)\n\u001b[32m   1324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(renderable, \u001b[33m\"\u001b[39m\u001b[33m__rich_console__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isclass(renderable):\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     render_iterable = \u001b[43mrenderable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__rich_console__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(renderable, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1327\u001b[39m     text_renderable = \u001b[38;5;28mself\u001b[39m.render_str(\n\u001b[32m   1328\u001b[39m         renderable, highlight=_options.highlight, markup=_options.markup\n\u001b[32m   1329\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\core.py:76\u001b[39m, in \u001b[36mExpr.__rich_console__\u001b[39m\u001b[34m(self, console, options)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m opts.interactive:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         rich_object = \u001b[43mto_rich\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsole_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsole_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     78\u001b[39m         rich_object = Text(\u001b[38;5;28mself\u001b[39m._noninteractive_repr())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\rich.py:70\u001b[39m, in \u001b[36mto_rich\u001b[39m\u001b[34m(expr, max_rows, max_columns, max_length, max_string, max_depth, console_width)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m to_rich_scalar(\n\u001b[32m     67\u001b[39m         expr, max_length=max_length, max_string=max_string, max_depth=max_depth\n\u001b[32m     68\u001b[39m     )\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_rich_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconsole_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconsole_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\_rich.py:331\u001b[39m, in \u001b[36mto_rich_table\u001b[39m\u001b[34m(tablish, max_rows, max_columns, max_length, max_string, max_depth, console_width)\u001b[39m\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m orig_ncols > \u001b[38;5;28mlen\u001b[39m(computed_cols):\n\u001b[32m    329\u001b[39m         table = table.select(*computed_cols)\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m result = \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pyarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# Now format the columns in order, stopping if the console width would\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[38;5;66;03m# be exceeded.\u001b[39;00m\n\u001b[32m    334\u001b[39m col_info = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\relations.py:615\u001b[39m, in \u001b[36mTable.to_pyarrow\u001b[39m\u001b[34m(self, params, limit, **kwargs)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;129m@experimental\u001b[39m\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_pyarrow\u001b[39m(\n\u001b[32m    609\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    613\u001b[39m     **kwargs: Any,\n\u001b[32m    614\u001b[39m ) -> pa.Table:\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pyarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\core.py:605\u001b[39m, in \u001b[36mExpr.to_pyarrow\u001b[39m\u001b[34m(self, params, limit, **kwargs)\u001b[39m\n\u001b[32m    575\u001b[39m \u001b[38;5;129m@experimental\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_pyarrow\u001b[39m(\n\u001b[32m    577\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    581\u001b[39m     **kwargs: Any,\n\u001b[32m    582\u001b[39m ) -> pa.Table | pa.Array | pa.Scalar:\n\u001b[32m    583\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute expression to a pyarrow object.\u001b[39;00m\n\u001b[32m    584\u001b[39m \n\u001b[32m    585\u001b[39m \u001b[33;03m    This method is eager and will execute the associated expression\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    603\u001b[39m \u001b[33;03m        If the passed expression is a Scalar, a pyarrow scalar is returned.\u001b[39;00m\n\u001b[32m    604\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_find_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_default\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pyarrow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\backends\\duckdb\\__init__.py:1380\u001b[39m, in \u001b[36mBackend.to_pyarrow\u001b[39m\u001b[34m(self, expr, params, limit, **kwargs)\u001b[39m\n\u001b[32m   1375\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mibis\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mduckdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconverter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DuckDBPyArrowData\n\u001b[32m   1377\u001b[39m table = \u001b[38;5;28mself\u001b[39m._to_duckdb_relation(\n\u001b[32m   1378\u001b[39m     expr, params=params, limit=limit, **kwargs\n\u001b[32m   1379\u001b[39m ).arrow()\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexpr\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__pyarrow_result__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_mapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDuckDBPyArrowData\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\expr\\types\\relations.py:583\u001b[39m, in \u001b[36mTable.__pyarrow_result__\u001b[39m\u001b[34m(self, table, schema, data_mapper)\u001b[39m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data_mapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mibis\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyArrowData \u001b[38;5;28;01mas\u001b[39;00m data_mapper\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata_mapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al033827\\OneDrive - Maxar Technologies Holdings Inc\\academic_repos\\Aegir-Eiders-Lightning-Lance\\.venv\\Lib\\site-packages\\ibis\\formats\\pyarrow.py:335\u001b[39m, in \u001b[36mPyArrowData.convert_table\u001b[39m\u001b[34m(cls, table, schema)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m table.schema == desired_schema:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m table\n\u001b[32m    334\u001b[39m arrays = [\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     \u001b[38;5;28mcls\u001b[39m.convert_column(\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m, dtype) \u001b[38;5;28;01mfor\u001b[39;00m name, dtype \u001b[38;5;129;01min\u001b[39;00m schema.items()\n\u001b[32m    336\u001b[39m ]\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pa.Table.from_arrays(arrays, schema=desired_schema)\n",
      "\u001b[31mTypeError\u001b[39m: 'pyarrow.lib.RecordBatchReader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "stg_pv = con.table(\"stg_pv_consolidated\")\n",
    "# exclude the uk dataset as it seems to have no intersects and severely distorts our matching % \n",
    "stg_pv = stg_pv.filter(_.dataset_name != 'uk_crowdsourced_pv_2020')\n",
    "\n",
    "@ibis.udf.scalar.builtin\n",
    "# signature returns GEOMETRY; use ibis geometry datatype\n",
    "def ST_GeomFromText(wkt: str) -> ibis.expr.datatypes.GeoSpatial:\n",
    "    '''Convert WKT to geometry'''\n",
    "stg_pv = stg_pv.mutate(geom=ST_GeomFromText(_.geometry))\n",
    "\n",
    "# sample \n",
    "stg_pv.sample(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacb2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stg_pv.aggregate(by=[\"h3_index_8\"], pv_count=_.unified_id.count(), pv_area=_.area_m2.sum()).order_by(ibis.desc(\"pv_count\")).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b97cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(stg_pv.aggregate(by=[\"h3_index_8\"], pv_count=_.unified_id.count(), pv_area=_.area_m2.sum()).order_by(ibis.desc(\"pv_count\")).head(20).visualize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load h3 duckdb extension and calculate coarser h3 index\n",
    "con.load_extension(\"h3\")\n",
    "# test returning column of h3 cells \n",
    "stg_pv.sql(\"SELECT h3_cell_to_parent(h3_index_8, 6) FROM stg_pv_consolidated LIMIT 10\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying (remote) Hub files with DuckDB\n",
    "\n",
    "fs = HfFileSystem()\n",
    "duckdb.register_filesystem(fs)\n",
    "# Query a remote file and get the result back as a dataframe\n",
    "# fs_query_file = \"hf://datasets/my-username/my-dataset-repo/data_dir/data.parquet\"\n",
    "# df = duckdb.query(f\"SELECT * FROM '{fs_query_file}' LIMIT 10\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mvp_workflow_header",
   "metadata": {},
   "source": [
    "## MVP Workflow: S2 Cell Matching with core-five Dataset\n",
    "\n",
    "This section implements the barebones workflow:\n",
    "1. Convert PV labels from DuckLake to GeoPandas\n",
    "2. Parse S2 cell IDs from core-five HuggingFace dataset structure\n",
    "3. Add S2 cell columns to PV dataframe at appropriate levels\n",
    "4. Match PV S2 cells with core-five S2 cells\n",
    "5. Set up basic xarray retrieval with virtualizarr optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1_header",
   "metadata": {},
   "source": [
    "### Step 1: Convert PV Labels to GeoPandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1_convert_geopandas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetched PV labels from DuckLake using ibis\n",
    "# Convert to pandas first; shuffle the rows (revise as dataset grows)\n",
    "pv_df = stg_pv.to_pandas().sample(frac=1)\n",
    "\n",
    "# Select a sample for MVP (e.g., 150-200 labels)\n",
    "# pv_sample = pv_df.sample(n=200, random_state=42)\n",
    "pv_sample = pv_df \n",
    "\n",
    "# Create GeoPandas dataframe and convert WKT geometry strings to shapely geometries\n",
    "pv_gdf = gpd.GeoDataFrame(pv_sample, geometry=pv_sample['geometry'].apply(shapely.wkt.loads), crs='EPSG:4326')\n",
    "\n",
    "print(f\"Loaded {len(pv_gdf)} PV labels into GeoPandas\")\n",
    "print(f\"Columns: {pv_gdf.columns.tolist()}\")\n",
    "pv_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615b16c",
   "metadata": {},
   "source": [
    "## Hugging Face Hub\n",
    "\n",
    "The [Hugging Face Hub](https://huggingface.co/docs/hub/index) is a Machine Learning platform with hundreds of thousands of open source and publicly available datasets, models, and interactive model demos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2_header",
   "metadata": {},
   "source": [
    "### Step 2: Parse S2 Cell IDs from core-five HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2_parse_s2_cells_optimized",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED: Use fs.glob() to get all files in ONE API call (avoids rate limiting)\n",
    "# Also parse BOTH parent dirs (level 10) AND child files (level 13) for hierarchical matching\n",
    "\n",
    "cache_file = Path(\"../data/core_five_s2_mapping.pkl\")\n",
    "core_five_root = \"datasets/gajeshladhar/core-five/src/datatree\"\n",
    "all_nc_files = None\n",
    "\n",
    "if cache_file.exists() and cache_file.stat().st_size > 0:\n",
    "    print(f\"Loading from cache: {cache_file}\")\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        s2_cell_mapping = pickle.load(f)\n",
    "    parent_cells_seen = set([info['token'] for info in s2_cell_mapping.values() if info['is_parent']])\n",
    "    print(f\"  Found {len(parent_cells_seen)} parent cells from cache\")\n",
    "    all_nc_files = [info['file_path'] for info in s2_cell_mapping.values() if not info['is_parent']]\n",
    "else:\n",
    "    print(\"Fetching all .nc files from core-five (single API call)...\")\n",
    "    all_nc_files = fs.glob(f\"{core_five_root}/**/*.nc\")  # ONE call gets all ~93k files\n",
    "    print(f\"Found {len(all_nc_files)} .nc files\")\n",
    "    \n",
    "    s2_cell_mapping = {}\n",
    "    parent_cells_seen = set()\n",
    "    \n",
    "    for file_path in tqdm(list(all_nc_files), desc=\"Parsing S2 cells\"):\n",
    "        parts = Path(file_path).parts\n",
    "        parent_token = parts[-2]  # e.g., \"1a220b\"\n",
    "        child_token = Path(file_path).stem  # e.g., \"1a220c04\"\n",
    "        \n",
    "        # Parse parent cell (only once per unique parent)\n",
    "        if parent_token not in parent_cells_seen:\n",
    "            try:\n",
    "                parent_cell_id = s2cell.token_to_cell_id(parent_token)\n",
    "                s2_cell_mapping[parent_cell_id] = {\n",
    "                    'token': parent_token,\n",
    "                    'level': s2cell.token_to_level(parent_token),\n",
    "                    'file_path': str(Path(file_path).parent),\n",
    "                    'is_parent': True,\n",
    "                    'children': []\n",
    "                }\n",
    "                parent_cells_seen.add(parent_token)\n",
    "            except:\n",
    "                print(f\"Failed to parse parent cell: {parent_token}\")\n",
    "                pass\n",
    "        \n",
    "        # Parse child cell\n",
    "        try:\n",
    "            child_cell_id = s2cell.token_to_cell_id(child_token)\n",
    "            parent_cell_id = s2cell.token_to_cell_id(parent_token)\n",
    "            \n",
    "            s2_cell_mapping[child_cell_id] = {\n",
    "                'token': child_token,\n",
    "                'level': s2cell.cell_id_to_level(child_cell_id),\n",
    "                'file_path': file_path,\n",
    "                'is_parent': False,\n",
    "                'parent_cell_id': parent_cell_id\n",
    "            }\n",
    "            \n",
    "            # Link child to parent\n",
    "            if parent_cell_id in s2_cell_mapping:\n",
    "                s2_cell_mapping[parent_cell_id]['children'].append(child_cell_id)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Save cache if successful\n",
    "    if s2_cell_mapping:\n",
    "        cache_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            pickle.dump(s2_cell_mapping, f)\n",
    "        print(f\"Saved to cache: {cache_file}\")\n",
    "\n",
    "# Analyze levels; we only expect 2 levels: one for parent_dir and a consistent s2 cell level for child dirs\n",
    "levels = sorted(list(set([info['level'] for info in s2_cell_mapping.values()]))) # sort so we start with parent dir level\n",
    "print(f\"\\nParsed {len(s2_cell_mapping)} total S2 cells\")\n",
    "print(f\"  Parent cells: {len(parent_cells_seen) if 'parent_cells_seen' in locals() else 'N/A'}\")\n",
    "print(f\"\\nS2 levels in core-five:\")\n",
    "for level in levels:\n",
    "    if level == min(levels):\n",
    "        print(f\"  Parent dir level: {level}; number of cells: {len(parent_cells_seen)}\")\n",
    "    else:\n",
    "        print(f\"  Child file level: {level}; number of cells: {len([info for info in s2_cell_mapping.values() if info['level'] == level])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f89d24",
   "metadata": {},
   "source": [
    "## Google S2 Geometric Spatial Indexing\n",
    "\n",
    "See python S2 library: [S2Cell Docs](https://docs.s2cell.aliddell.com/en/stable/index.html)\n",
    "\n",
    "See details: https://learn.microsoft.com/en-us/kusto/query/geo-point-to-s2cell-function?view=microsoft-fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3_header",
   "metadata": {},
   "source": [
    "### Step 3: Add S2 Cell Columns to PV DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step3_add_s2_columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which S2 levels to use based on core-five dataset\n",
    "# We'll add columns for each level present in core-five\n",
    "\n",
    "print(f\"Adding S2 cell columns for levels: {levels}\")\n",
    "\n",
    "# For each PV label, compute S2 cell IDs at each target level using centroid\n",
    "for level in levels:\n",
    "    col_name = f's2_cell_lvl_{level}'\n",
    "    pv_gdf[col_name] = pv_gdf.apply(\n",
    "        lambda row: s2cell.lat_lon_to_cell_id(\n",
    "            row['centroid_lat'], \n",
    "            row['centroid_lon'], \n",
    "            level\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    print(f\"  Added column: {col_name}\")\n",
    "\n",
    "print(f\"\\nPV GeoDataFrame now has {len(pv_gdf.columns)} columns\")\n",
    "print(f\"New S2 columns: {[col for col in pv_gdf.columns if col.startswith('s2_cell_lvl')]}\")\n",
    "pv_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4_header",
   "metadata": {},
   "source": [
    "### Step 4: Match PV S2 Cells with core-five S2 Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step4_match_cells",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHILD-ONLY MATCHING: Only match exact child cells (level 13)\n",
    "# Parent matching would include ALL children (false positives)\n",
    "# We only want the specific child cell where the PV label is located\n",
    "\n",
    "def find_matches_child_only(row, s2_mapping):\n",
    "    \"\"\"Match only at child level for precise location\"\"\"\n",
    "    matches = set()\n",
    "    \n",
    "    # Only match exact child cell (level 13)\n",
    "    if 's2_cell_lvl_13' in row:\n",
    "        child_id = row['s2_cell_lvl_13']\n",
    "        if child_id in s2_mapping and not s2_mapping[child_id].get('is_parent', False):\n",
    "            matches.add(s2_mapping[child_id]['file_path'])\n",
    "    \n",
    "    # NOTE: We still record parent cell IDs in the dataframe for reference,\n",
    "    # but don't use them for matching to avoid false positives\n",
    "    \n",
    "    return list(matches)\n",
    "\n",
    "pv_gdf['matched_files'] = pv_gdf.apply(lambda row: find_matches_child_only(row, s2_cell_mapping), axis=1)\n",
    "pv_gdf['num_matches'] = pv_gdf['matched_files'].apply(len)\n",
    "\n",
    "# Statistics\n",
    "total = len(pv_gdf)\n",
    "with_matches = (pv_gdf['num_matches'] > 0).sum()\n",
    "print(f\"\\nMatching Results:\")\n",
    "print(f\"  Total PV labels: {total:,}\")\n",
    "print(f\"  Labels with matches: {with_matches:,} ({with_matches/total*100:.2f}%)\")\n",
    "print(f\"  Labels without matches: {total - with_matches:,}\")\n",
    "print(f\"  Average matches per label: {pv_gdf['num_matches'].mean():.2f}\")\n",
    "\n",
    "pv_gdf[pv_gdf['num_matches'] > 0][['unified_id', 'centroid_lat', 'centroid_lon', 'num_matches']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "granular_s2_header",
   "metadata": {},
   "source": [
    "### Step 4.5: Add Granular S2 Cells for Precise PV Label Capture\n",
    "\n",
    "Based on S2 Cell statistics (http://s2geometry.io/resources/s2cell_statistics):\n",
    "- **Level 13** (current): ~850m - 1185m edge length, ~0.76 - 1.59 km area\n",
    "- **Level 17**: ~53m - 77m edge length, ~2970 - 6227 m area  **RECOMMENDED** \n",
    "- **Level 18**: ~27m - 38m edge length, ~742 - 1556 m area \n",
    "- **Level 19**: ~13m - 19m edge length, ~185 - 389 m area \n",
    "<!-- - **Level 20**: ~7m - 10m edge length, ~46 - 97 m area -->\n",
    "\n",
    "Level 19 provides ~15m resolution, ideal for capturing individual PV installations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add_granular_s2_cells",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add level 19 S2 cells for precise PV label capture\n",
    "S2_CELL_LVL = 17\n",
    "def add_granular_s2_cell(row, level=19):\n",
    "    \"\"\"\n",
    "    Add a granular S2 cell ID at specified level for precise spatial indexing.\n",
    "\n",
    "    Args:\n",
    "        row: DataFrame row with 'centroid' geometry\n",
    "        level: S2 cell level (default 19 for ~15m resolution)\n",
    "    \"\"\"\n",
    "    cell_id = s2cell.lat_lon_to_cell_id(row['centroid_lat'], row['centroid_lon'], level)\n",
    "    return cell_id\n",
    "\n",
    "# Add level 18 cells to our PV dataframe (better size for image chips)\n",
    "print(f\"Adding level {S2_CELL_LVL} S2 cells for PV label capture...\")\n",
    "pv_gdf[f's2_cell_lvl_{S2_CELL_LVL}'] = pv_gdf.apply(lambda row: add_granular_s2_cell(row, level=17), axis=1)\n",
    "\n",
    "print(f\"\\nS2 Cell levels now available:\")\n",
    "print(f\"  - Level 10 (parent): ~7-10 km edge, for directory matching\")\n",
    "print(f\"  - Level 13 (child): ~850m-1185m edge, for file matching\")\n",
    "print(f\"  - Level 17 (granular): ~53m - 77m edge length, for image chip-sized PV capture\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample PV labels with all S2 levels:\")\n",
    "# NOTE: we have several labels with NULL unified_id (must be from a null field in our coalesce or hash processing during stg)\n",
    "display(pv_gdf[['unified_id', 's2_cell_lvl_10', 's2_cell_lvl_13', f's2_cell_lvl_{S2_CELL_LVL}']].sample(5))\n",
    "# get count of matching labels grouped by dataset\n",
    "pv_gdf[pv_gdf['num_matches'] > 0].groupby('dataset_name')['num_matches'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5_header",
   "metadata": [],
   "source": [
    "### Step 5: Basic xarray Retrieval with VirtualiZarr Groundwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step5_xarray_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from obstore.store import from_url\n",
    "from virtualizarr import open_virtual_dataset\n",
    "from virtualizarr.parsers import HDFParser\n",
    "from virtualizarr.registry import ObjectStoreRegistry\n",
    "\n",
    "# Set up object store for HuggingFace dataset access\n",
    "# Note: HuggingFace uses HTTPS, so we'll use HTTP store\n",
    "bucket = \"https://huggingface.co\"\n",
    "store = from_url(bucket)\n",
    "registry = ObjectStoreRegistry({bucket: store})\n",
    "\n",
    "print(\"Object store registry initialized for HuggingFace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step5_load_in_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: In-memory loading with fsspec + h5netcdf (no local files)\n",
    "# This opens the file via HTTP and reads into memory without saving to disk\n",
    "\n",
    "import fsspec\n",
    "\n",
    "SAMPLE_CRS = None\n",
    "\n",
    "num_row_matches = (pv_gdf['num_matches'] > 0).sum()\n",
    "rand_sample_idx = random.randint(0, num_row_matches - 1)\n",
    "if num_row_matches > 0:\n",
    "    sample_file = pv_gdf[pv_gdf['num_matches'] > 0].iloc[rand_sample_idx]['matched_files'][0]\n",
    "    \n",
    "    # Construct HuggingFace resolve URL\n",
    "    filename = \"/\".join(Path(sample_file).parts[3:])  # Remove 'datasets/gajeshladhar/core-five/'\n",
    "    url = f\"https://huggingface.co/datasets/gajeshladhar/core-five/resolve/main/{filename}\"\n",
    "    \n",
    "    print(f\"Loading from URL: {url}\")\n",
    "    \n",
    "    # Open file via HTTP using fsspec (in-memory)\n",
    "    with fsspec.open(url, 'rb') as f:\n",
    "        # Use h5netcdf engine (supports file-like objects)\n",
    "        tree = xr.open_datatree(f, engine='h5netcdf')\n",
    "        tree = tree.load()  # Load data into memory\n",
    "        \n",
    "        print(f\"\\nDataTree structure:\")\n",
    "        print(tree)\n",
    "        \n",
    "        # Access modalities\n",
    "        if \"hr/data\" in tree:\n",
    "            hr_data = tree[\"hr/data\"]\n",
    "            print(f\"\\nHigh-res RGB: {hr_data.dims}\")\n",
    "        \n",
    "        if \"s2\" in tree:\n",
    "            s2_data = tree[\"s2\"]\n",
    "            print(f\"Sentinel-2: {s2_data.dims}\")\n",
    "\n",
    "        # CRS varies by S2 Cell image but is consistent within each .nc file between the modalities\n",
    "        SAMPLE_CRS = tree.crs\n",
    "\n",
    "else:\n",
    "    print(\"No matches found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare matching gdf with s2 cells vs direct pv label intersections with the tree.polygon geom\n",
    "# see ibis geospatial functions here: https://ibis-project.org/reference/expression-geospatial\n",
    "stg_pv.filter(stg_pv.geom.intersects(tree.polygon)).to_pandas().shape[0]\n",
    "# note that the lower number of matches here is expected as this is only matching with a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test collecting the polygons of multiple images in a list (requires loading entire .nc file! run for performance comparison)\n",
    "core_five_samples = random.sample(all_nc_files, 3) if 'all_nc_files' in locals() else random.sample(fs.glob(f\"{core_five_root}/**/*.nc\"), 3)\n",
    "sample_polygons = []\n",
    "for sample in tqdm(core_five_samples, desc=\"Collecting polygons\"):\n",
    "    filename = \"/\".join(Path(sample).parts[3:])  # Remove 'datasets/gajeshladhar/core-five/'\n",
    "    url = f\"https://huggingface.co/datasets/gajeshladhar/core-five/resolve/main/{filename}\"\n",
    "    with fsspec.open(url, 'rb') as sf:\n",
    "        tr = xr.open_datatree(sf, engine='h5netcdf')\n",
    "        sample_polygons.append(tr.polygon)\n",
    "print(sample_polygons)\n",
    "# good comparison benchmark for performance benefits of S2 matching and spatial indexing for STAC matching later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pixel_bbox_converters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for converting geometries to bounding boxes for SAM\n",
    "# needs to be declared after xarray load so CRS is available\n",
    "import s2cell\n",
    "# older library that was archived in 2023 but using as workaround while duckdb extension is updated: https://github.com/sidewalklabs/s2sphere\n",
    "import s2sphere as s2\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "\n",
    "# TODO: implement required proj and transform for buffer in meters \n",
    "def s2_cell_to_geo_bbox(s2_cell_id, buffer_m=None):\n",
    "    \"\"\"\n",
    "    Convert an S2 cell ID to bbox coordinates for SAM.\n",
    "    \n",
    "    Args:\n",
    "        s2_cell_id: S2 cell ID (int)\n",
    "        buffer_m: Buffer size in meters (default 15m for level 19)\n",
    "    \n",
    "    Returns:\n",
    "        list: [left, bottom, right, top] in EPSG:4326\n",
    "    \"\"\"\n",
    "    # Get S2 cell in s2sphere and convert to bounding rectangle coords\n",
    "    cell_id = s2.CellId(sample_s2_cell)\n",
    "    s2Cell = s2.Cell(cell_id) \n",
    "    rect_bound = s2Cell.get_rect_bound()\n",
    "    return [\n",
    "        rect_bound.lng_lo().degrees,  # left\n",
    "        rect_bound.lat_lo().degrees,  # bottom\n",
    "        rect_bound.lng_hi().degrees,  # right\n",
    "        rect_bound.lat_hi().degrees   # top\n",
    "    ]\n",
    "\n",
    "# Pixel coordinate conversion functions with CRS transformation\n",
    "# Copy this entire cell into your notebook to replace the existing pixel_bbox_converters cell\n",
    "\n",
    "from affine import Affine\n",
    "from pyproj import Transformer\n",
    "\n",
    "def get_transform_from_coords(x_coords, y_coords):\n",
    "    \"\"\"\n",
    "    Calculate affine transform from xarray coordinates.\n",
    "    \n",
    "    Args:\n",
    "        x_coords: xarray x coordinates (in projected units, e.g., meters)\n",
    "        y_coords: xarray y coordinates (in projected units, e.g., meters)\n",
    "    \n",
    "    Returns:\n",
    "        Affine: Affine transform object\n",
    "    \"\"\"\n",
    "    # Calculate pixel size from coordinate spacing\n",
    "    pixel_width = float(x_coords[1] - x_coords[0])\n",
    "    pixel_height = float(y_coords[1] - y_coords[0])\n",
    "    \n",
    "    # Upper-left corner (coords are pixel centers)\n",
    "    x_min = float(x_coords[0]) - pixel_width / 2\n",
    "    y_max = float(y_coords[0]) - pixel_height / 2\n",
    "    \n",
    "    # Create affine transform\n",
    "    transform = Affine(pixel_width, 0.0, x_min,\n",
    "                      0.0, pixel_height, y_max)\n",
    "    \n",
    "    print(f\" Transform: pixel_width={pixel_width:.6f}m, pixel_height={pixel_height:.6f}m\")\n",
    "    return transform\n",
    "\n",
    "def get_chip_transform(chip_metadata):\n",
    "    \"\"\"\n",
    "    Create a local geotransform for an image chip.\n",
    "    \n",
    "    Args:\n",
    "        chip_metadata: Dict from display_image_chip() with 'x_coords', 'y_coords'\n",
    "    \n",
    "    Returns:\n",
    "        Affine: Affine transform for the chip's local coordinate system\n",
    "    \n",
    "    Example:\n",
    "        >>> chip_rgb, chip_meta = display_image_chip(tree, chip_size=512)\n",
    "        >>> chip_transform = get_chip_transform(chip_meta)\n",
    "        >>> bbox_pixels = geometry_to_bbox_pixels(geom, chip_transform, dst_crs=chip_meta['crs'])\n",
    "    \"\"\"\n",
    "    return get_transform_from_coords(chip_metadata['x_coords'], chip_metadata['y_coords'])\n",
    "\n",
    "def geo_to_pixel_coords(lon, lat, transform, src_crs='EPSG:4326', dst_crs=SAMPLE_CRS):\n",
    "    \"\"\"\n",
    "    Convert geographic coordinates to pixel coordinates.\n",
    "    \n",
    "    Args:\n",
    "        lon: Longitude in degrees (or x in projected units if src_crs matches image)\n",
    "        lat: Latitude in degrees (or y in projected units if src_crs matches image)\n",
    "        transform: Affine transform from get_transform_from_coords()\n",
    "        src_crs: Source CRS (default 'EPSG:4326' for lat/lon)\n",
    "        dst_crs: Destination CRS (e.g., 'EPSG:32610' for UTM 30N). If None, no transformation.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (col, row) pixel coordinates\n",
    "    \"\"\"\n",
    "    # Transform to image CRS if needed\n",
    "    if dst_crs is not None and src_crs != dst_crs:\n",
    "        transformer = Transformer.from_crs(src_crs, dst_crs, always_xy=True)\n",
    "        x, y = transformer.transform(lon, lat)\n",
    "    else:\n",
    "        x, y = lon, lat\n",
    "    \n",
    "    # Convert to pixel coordinates\n",
    "    inv_transform = ~transform\n",
    "    col, row = inv_transform * (x, y)\n",
    "    return col, row\n",
    "\n",
    "def geometry_to_bbox_pixels(geometry, transform, src_crs='EPSG:4326', dst_crs=SAMPLE_CRS):\n",
    "    \"\"\"\n",
    "    Convert a Shapely geometry to pixel bbox coordinates.\n",
    "    \n",
    "    Args:\n",
    "        geometry: Shapely geometry in src_crs\n",
    "        transform: Affine transform from get_transform_from_coords()\n",
    "        src_crs: Source CRS of geometry (default 'EPSG:4326')\n",
    "        dst_crs: Image CRS. If None, assumes geometry already in image CRS.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x_min, y_min, x_max, y_max) in pixel coordinates\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = geometry.bounds\n",
    "    \n",
    "    # Convert corners to pixel coordinates\n",
    "    x_min, y_max_px = geo_to_pixel_coords(minx, maxy, transform, src_crs, dst_crs)\n",
    "    x_max, y_min_px = geo_to_pixel_coords(maxx, miny, transform, src_crs, dst_crs)\n",
    "    \n",
    "    return (x_min, y_min_px, x_max, y_max_px)\n",
    "\n",
    "def s2_cell_to_bbox_pixels(s2_cell_id, transform, dst_crs=SAMPLE_CRS, buffer_m=15):\n",
    "    \"\"\"\n",
    "    Convert an S2 cell ID to pixel bbox coordinates.\n",
    "    \n",
    "    Args:\n",
    "        s2_cell_id: S2 cell ID (int)\n",
    "        transform: Affine transform from get_transform_from_coords()\n",
    "        dst_crs: Image CRS. If None, no transformation.\n",
    "        buffer_m: Buffer size in meters (default 15m for level 19)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x_min, y_min, x_max, y_max) in pixel coordinates\n",
    "    \"\"\"\n",
    "    import s2cell\n",
    "    import math\n",
    "    \n",
    "    # Get S2 cell center in lat/lon\n",
    "    lat, lon = s2cell.cell_id_to_lat_lon(s2_cell_id)\n",
    "    \n",
    "    # Approximate degrees per meter at this latitude\n",
    "    # TODO: convert to use duckdb geography which has function for this https://github.com/paleolimbot/duckdb-geography/blob/main/docs/function-reference.md \n",
    "    deg_per_m_lat = 1 / 111000\n",
    "    deg_per_m_lon = 1 / (111000 * math.cos(math.radians(lat)))\n",
    "    \n",
    "    # Create geographic bbox\n",
    "    half_buffer_lat = buffer_m * deg_per_m_lat\n",
    "    half_buffer_lon = buffer_m * deg_per_m_lon\n",
    "    \n",
    "    minx = lon - half_buffer_lon\n",
    "    miny = lat - half_buffer_lat\n",
    "    maxx = lon + half_buffer_lon\n",
    "    maxy = lat + half_buffer_lat\n",
    "    \n",
    "    # Convert to pixel coordinates\n",
    "    x_min, y_max_px = geo_to_pixel_coords(minx, maxy, transform, 'EPSG:4326', dst_crs)\n",
    "    x_max, y_min_px = geo_to_pixel_coords(maxx, miny, transform, 'EPSG:4326', dst_crs)\n",
    "    \n",
    "    return (x_min, y_min_px, x_max, y_max_px)\n",
    "\n",
    "print(\" Pixel coordinate converters ready (with CRS transformation)\")\n",
    "print(\"  - get_transform_from_coords(): Calculate transform from xarray coords\")\n",
    "print(\"  - geo_to_pixel_coords(): Convert lon/lat to pixel col/row\")\n",
    "print(\"  - geometry_to_bbox_pixels(): Convert geometry to pixel bbox\")\n",
    "print(\"  - s2_cell_to_bbox_pixels(): Convert S2 cell to pixel bbox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image_display_fix_header",
   "metadata": {},
   "source": [
    "### Image Display Helper - FIX for 'Invalid shape' Error\n",
    "\n",
    "The `hr/data` group has shape `(band, y, x)` but matplotlib expects `(y, x, band)` for RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825eaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display core-five imagery (fixes transpose issue)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "\n",
    "def _calculate_chip_position_from_geometry(geometry, x_coords, y_coords, chip_size, crs):\n",
    "    \"\"\"\n",
    "    Calculate chip position to center on a geometry.\n",
    "    \n",
    "    Args:\n",
    "        geometry: Shapely geometry in EPSG:4326\n",
    "        x_coords: Full image x coordinates (projected)\n",
    "        y_coords: Full image y coordinates (projected)\n",
    "        chip_size: Size of chip in pixels\n",
    "        crs: Image CRS (e.g., 'EPSG:32630')\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (y_start, x_start) pixel positions\n",
    "    \"\"\"\n",
    "    # Get geometry centroid in lat/lon\n",
    "    centroid = geometry.centroid\n",
    "    lon, lat = centroid.x, centroid.y\n",
    "    \n",
    "    # Transform to image CRS\n",
    "    if crs and crs != 'EPSG:4326':\n",
    "        transformer = Transformer.from_crs('EPSG:4326', crs, always_xy=True)\n",
    "        x_proj, y_proj = transformer.transform(lon, lat)\n",
    "    else:\n",
    "        x_proj, y_proj = lon, lat\n",
    "    \n",
    "    # Find nearest pixel indices\n",
    "    x_idx = np.argmin(np.abs(x_coords - x_proj))\n",
    "    y_idx = np.argmin(np.abs(y_coords - y_proj))\n",
    "    \n",
    "    # Calculate chip bounds centered on this point\n",
    "    x_start = max(0, x_idx - chip_size // 2)\n",
    "    y_start = max(0, y_idx - chip_size // 2)\n",
    "    \n",
    "    # Ensure chip doesn't go beyond image bounds\n",
    "    if x_start + chip_size > len(x_coords):\n",
    "        x_start = len(x_coords) - chip_size\n",
    "    if y_start + chip_size > len(y_coords):\n",
    "        y_start = len(y_coords) - chip_size\n",
    "    \n",
    "    # Ensure non-negative\n",
    "    x_start = max(0, x_start)\n",
    "    y_start = max(0, y_start)\n",
    "    \n",
    "    return y_start, x_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024dd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chip_as_geotiff(chip_rgb, chip_metadata, output_path):\n",
    "    \"\"\"\n",
    "    Save an image chip as a GeoTIFF with proper geospatial metadata.\n",
    "\n",
    "    Args:\n",
    "        chip_rgb: numpy array of shape (height, width, 3) with uint8 values\n",
    "        chip_metadata: dict with 'x_coords', 'y_coords', 'crs' from display_image_chip\n",
    "        output_path: Path to save the GeoTIFF\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved GeoTIFF\n",
    "    \"\"\"\n",
    "    import rasterio\n",
    "    from rasterio.transform import from_bounds\n",
    "\n",
    "    # Get chip bounds from coordinates\n",
    "    x_coords = chip_metadata['x_coords']\n",
    "    y_coords = chip_metadata['y_coords']\n",
    "    bounds = (x_coords.min(), y_coords.min(), x_coords.max(), y_coords.max())\n",
    "\n",
    "    # Get CRS\n",
    "    crs = chip_metadata['crs']\n",
    "\n",
    "    # Create geotransform from bounds\n",
    "    height, width = chip_rgb.shape[:2]\n",
    "    transform = from_bounds(*bounds, width, height)\n",
    "\n",
    "    # Ensure uint8 dtype\n",
    "    if chip_rgb.dtype != np.uint8:\n",
    "        if chip_rgb.max() <= 1.0:\n",
    "            chip_rgb = (chip_rgb * 255).astype(np.uint8)\n",
    "        else:\n",
    "            chip_rgb = chip_rgb.astype(np.uint8)\n",
    "\n",
    "    # Save as GeoTIFF\n",
    "    with rasterio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=3,\n",
    "        dtype='uint8',\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "        compress='deflate'\n",
    "    ) as dst:\n",
    "        # Write RGB bands\n",
    "        for i in range(3):\n",
    "            dst.write(chip_rgb[:, :, i], i + 1)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image_display_helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_chip(tree, chip_size=512, random_chip=True, data_type='hr', combine_rgb_bands=False, \n",
    "                       y_start=None, x_start=None, center_on_geometry=None):\n",
    "    \"\"\"\n",
    "    Display imagery from core-five datatree (supports both HR and Sentinel-2).\n",
    "    \n",
    "    Args:\n",
    "        tree: xarray DataTree from core-five\n",
    "        chip_size: Size of chip to display (default 512x512)\n",
    "        random_chip: If True, select random location; else use center (ignored if other params provided)\n",
    "        data_type: 'hr' for high-res RGB or 's2' for Sentinel-2\n",
    "        combine_rgb_bands: For S2, force RGB composition from B02/B03/B04\n",
    "        y_start: Optional fixed y start position (overrides random_chip)\n",
    "        x_start: Optional fixed x start position (overrides random_chip)\n",
    "        center_on_geometry: Optional Shapely geometry to center chip on (overrides random_chip)\n",
    "                           Geometry should be in EPSG:4326 (lat/lon)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (chip_rgb, chip_metadata) where:\n",
    "            - chip_rgb: numpy array of shape (chip_size, chip_size, 3)\n",
    "            - chip_metadata: dict with 'y_start', 'x_start', 'x_coords', 'y_coords', 'crs'\n",
    "    \"\"\"\n",
    "\n",
    "    # Pick latest time\n",
    "    latest_time_idx = -1\n",
    "\n",
    "    if data_type == 'hr':\n",
    "        # HR data: shape is (band, y, x) with 3 RGB bands\n",
    "        hr_data = tree['hr']['data'].values\n",
    "        n_bands, height, width = hr_data.shape\n",
    "        print(f\"HR image shape: {hr_data.shape} (band, y, x)\")\n",
    "        \n",
    "        # Get coordinates and CRS\n",
    "        x_coords = tree['hr'].ds.x.values\n",
    "        y_coords = tree['hr'].ds.y.values\n",
    "        crs = tree.attrs.get('crs', None)\n",
    "        \n",
    "        # Select chip location\n",
    "        if y_start is None or x_start is None:\n",
    "            if center_on_geometry is not None:\n",
    "                # Center chip on the provided geometry\n",
    "                y_start, x_start = _calculate_chip_position_from_geometry(\n",
    "                    center_on_geometry, x_coords, y_coords, chip_size, crs\n",
    "                )\n",
    "                print(f\"Centering chip on geometry (centroid: {center_on_geometry.centroid.coords[0]})\")\n",
    "            elif random_chip:\n",
    "                y_start = np.random.randint(0, max(1, height - chip_size))\n",
    "                x_start = np.random.randint(0, max(1, width - chip_size))\n",
    "            else:\n",
    "                y_start = (height - chip_size) // 2\n",
    "                x_start = (width - chip_size) // 2\n",
    "        \n",
    "        # Extract chip\n",
    "        chip = hr_data[:, y_start:y_start+chip_size, x_start:x_start+chip_size]\n",
    "        \n",
    "        # Transpose from (band, y, x) to (y, x, band) for matplotlib\n",
    "        chip_rgb = np.transpose(chip, (1, 2, 0))\n",
    "        print(f\"Chip shape after transpose: {chip_rgb.shape} (y, x, band)\")\n",
    "        \n",
    "        # Extract chip coordinates\n",
    "        chip_x_coords = x_coords[x_start:x_start+chip_size]\n",
    "        chip_y_coords = y_coords[y_start:y_start+chip_size]\n",
    "        \n",
    "        title = f\"HR RGB {chip_size}x{chip_size} chip\\nLocation: y={y_start}, x={x_start}\"\n",
    "        \n",
    "    elif data_type == 's2':\n",
    "        # S2 data: shape is (time, y, x) for each band\n",
    "        print(f\"Using sensor with data_vars: {tree['s2'].data_vars}\")\n",
    "        s2_ds = tree['s2'].ds\n",
    "        \n",
    "        # Get coordinates and CRS\n",
    "        x_coords = s2_ds.x.values\n",
    "        y_coords = s2_ds.y.values\n",
    "        crs = tree.attrs.get('crs', None)\n",
    "        \n",
    "        print(f\"S2 time dimension: {len(s2_ds.time)} timestamps\")\n",
    "        print(f\"Using latest timestamp: {s2_ds.time.values[latest_time_idx]}\")\n",
    "        \n",
    "        # Check if 'visual' band exists (pre-computed RGB)\n",
    "        if 'visual' in s2_ds.data_vars and not combine_rgb_bands:\n",
    "            print(\"Using pre-computed 'visual' band\")\n",
    "            s2_data = s2_ds['visual'].isel(time=latest_time_idx).values\n",
    "            height, width = s2_data.shape\n",
    "            \n",
    "            # Select chip location\n",
    "            if y_start is None or x_start is None:\n",
    "                if center_on_geometry is not None:\n",
    "                    y_start, x_start = _calculate_chip_position_from_geometry(\n",
    "                        center_on_geometry, x_coords, y_coords, chip_size, crs\n",
    "                    )\n",
    "                    print(f\"Centering chip on geometry (centroid: {center_on_geometry.centroid.coords[0]})\")\n",
    "                elif random_chip:\n",
    "                    y_start = np.random.randint(0, max(1, height - chip_size))\n",
    "                    x_start = np.random.randint(0, max(1, width - chip_size))\n",
    "                else:\n",
    "                    y_start = (height - chip_size) // 2\n",
    "                    x_start = (width - chip_size) // 2\n",
    "            \n",
    "            # Extract chip (single band grayscale or RGB if visual is 3-channel)\n",
    "            chip = s2_data[y_start:y_start+chip_size, x_start:x_start+chip_size]\n",
    "            \n",
    "            # If single channel, convert to RGB by repeating\n",
    "            if chip.ndim == 2:\n",
    "                chip_rgb = np.stack([chip, chip, chip], axis=-1)\n",
    "            else:\n",
    "                chip_rgb = chip\n",
    "                \n",
    "        else:\n",
    "            # Create RGB from B04 (Red), B03 (Green), B02 (Blue)\n",
    "            print(\"Creating RGB from B04 (Red), B03 (Green), B02 (Blue)\")\n",
    "            b04 = s2_ds['B04'].isel(time=latest_time_idx).values  # Red\n",
    "            b03 = s2_ds['B03'].isel(time=latest_time_idx).values  # Green\n",
    "            b02 = s2_ds['B02'].isel(time=latest_time_idx).values  # Blue\n",
    "            s2_data = np.stack([b04, b03, b02], axis=-1)\n",
    "            \n",
    "            height, width = b04.shape\n",
    "            \n",
    "            # Select chip location\n",
    "            if y_start is None or x_start is None:\n",
    "                if center_on_geometry is not None:\n",
    "                    y_start, x_start = _calculate_chip_position_from_geometry(\n",
    "                        center_on_geometry, x_coords, y_coords, chip_size, crs\n",
    "                    )\n",
    "                    print(f\"Centering chip on geometry (centroid: {center_on_geometry.centroid.coords[0]})\")\n",
    "                elif random_chip:\n",
    "                    y_start = np.random.randint(0, max(1, height - chip_size))\n",
    "                    x_start = np.random.randint(0, max(1, width - chip_size))\n",
    "                else:\n",
    "                    y_start = (height - chip_size) // 2\n",
    "                    x_start = (width - chip_size) // 2\n",
    "            \n",
    "            # Extract chips and stack as RGB\n",
    "            r = b04[y_start:y_start+chip_size, x_start:x_start+chip_size]\n",
    "            g = b03[y_start:y_start+chip_size, x_start:x_start+chip_size]\n",
    "            b = b02[y_start:y_start+chip_size, x_start:x_start+chip_size]\n",
    "            \n",
    "            chip_rgb = np.stack([r, g, b], axis=-1)\n",
    "        \n",
    "        print(f\"S2 image shape: {s2_data.shape if 'visual' in s2_ds.data_vars else b04.shape} (y, x)\")\n",
    "        print(f\"Chip shape: {chip_rgb.shape} (y, x, band)\")\n",
    "        \n",
    "        # Extract chip coordinates\n",
    "        chip_x_coords = x_coords[x_start:x_start+chip_size]\n",
    "        chip_y_coords = y_coords[y_start:y_start+chip_size]\n",
    "        \n",
    "        title = f\"S2 RGB {chip_size}x{chip_size} chip\\nLocation: y={y_start}, x={x_start}\"\n",
    "    \n",
    "    elif data_type == 'landsat':\n",
    "\n",
    "        print(f\"Using sensor with data_vars: {tree['landsat'].data_vars}\")\n",
    "        landsat_ds = tree['landsat'].ds\n",
    "        \n",
    "        # Get coordinates and CRS\n",
    "        x_coords = landsat_ds.x.values\n",
    "        y_coords = landsat_ds.y.values\n",
    "        crs = tree.attrs.get('crs', None)\n",
    "\n",
    "        print(f\"Landsat time dimension: {len(landsat_ds.time)} timestamps\")\n",
    "        print(f\"Using latest timestamp: {landsat_ds.time.values[latest_time_idx]}\")\n",
    "\n",
    "        print(\"Composing RGB from Landsat red, blue, and green bands...\")\n",
    "\n",
    "        red = landsat_ds['red'].isel(time=latest_time_idx).values\n",
    "        green = landsat_ds['green'].isel(time=latest_time_idx).values\n",
    "        blue = landsat_ds['blue'].isel(time=latest_time_idx).values\n",
    "        landsat_data = np.stack([red, green, blue], axis=-1)\n",
    "\n",
    "        height, width = red.shape\n",
    "\n",
    "        # Select chip location\n",
    "        if y_start is None or x_start is None:\n",
    "            if center_on_geometry is not None:\n",
    "                y_start, x_start = _calculate_chip_position_from_geometry(\n",
    "                    center_on_geometry, x_coords, y_coords, chip_size, crs\n",
    "                )\n",
    "                print(f\"Centering chip on geometry (centroid: {center_on_geometry.centroid.coords[0]})\")\n",
    "            elif random_chip:\n",
    "                y_start = np.random.randint(0, max(1, height - chip_size))\n",
    "                x_start = np.random.randint(0, max(1, width - chip_size))\n",
    "            else:\n",
    "                y_start = (height - chip_size) // 2\n",
    "                x_start = (width - chip_size) // 2\n",
    "        \n",
    "        # Extract chip\n",
    "        chip_rgb = landsat_data[y_start:y_start+chip_size, x_start:x_start+chip_size]\n",
    "\n",
    "        print(f\"Landsat image shape: {landsat_data.shape} (y, x, band)\")\n",
    "        print(f\"Chip shape: {chip_rgb.shape} (y, x, band)\")\n",
    "        \n",
    "        # Extract chip coordinates\n",
    "        chip_x_coords = x_coords[x_start:x_start+chip_size]\n",
    "        chip_y_coords = y_coords[y_start:y_start+chip_size]\n",
    "        \n",
    "        title = f\"Landsat RGB {chip_size}x{chip_size} chip\\nLocation: y={y_start}, x={x_start}\"\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown data_type: {data_type}. Use 'hr' or 's2'.\")\n",
    "    \n",
    "    # Normalize to 0-1 range if needed\n",
    "    if chip_rgb.max() > 1.0:\n",
    "        chip_rgb = chip_rgb / chip_rgb.max()\n",
    "    \n",
    "    # only render if we're not centering on a geometry\n",
    "    if center_on_geometry is None:\n",
    "        # Display\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(chip_rgb)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # Create metadata dict\n",
    "    chip_metadata = {\n",
    "        'y_start': y_start,\n",
    "        'x_start': x_start,\n",
    "        'x_coords': chip_x_coords,\n",
    "        'y_coords': chip_y_coords,\n",
    "        'crs': crs\n",
    "    }\n",
    "    \n",
    "    return chip_rgb, chip_metadata\n",
    "\n",
    "# Example usage:\n",
    "# Random chip:\n",
    "# chip_hr, meta = display_image_chip(tree, chip_size=512, random_chip=True, data_type='hr')\n",
    "# \n",
    "# Chip centered on PV label (for bbox visualization):\n",
    "# chip_hr, meta = display_image_chip(tree, chip_size=512, center_on_geometry=pv_label.geometry, data_type='hr')\n",
    "# chip_transform = get_chip_transform(meta)\n",
    "# bbox_pixels = geometry_to_bbox_pixels(pv_label.geometry, chip_transform, dst_crs=meta['crs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18253fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_chip, hr_meta = display_image_chip(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10m resolution is ~30-40x coarser than HR, adjust chip size accordingly\n",
    "s2_chip, s2_meta = display_image_chip(tree, data_type='s2', chip_size=96, combine_rgb_bands=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landsat's 30m gsd is 3x coarser than s2's 10m, so adjust chip size accordingly\n",
    "landsat_chip, landsat_meta = display_image_chip(tree, data_type='landsat', chip_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display full tree hr image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def display_full_image(tree, data_type='hr', combine_rgb_bands=False, normalize=True):\n",
    "    \"\"\"\n",
    "    Display full imagery from core-five datatree (supports both HR and Sentinel-2).\n",
    "    \n",
    "    Args:\n",
    "        tree: xarray DataTree from core-five\n",
    "        data_type: 'hr' for high-res RGB or 's2' for Sentinel-2\n",
    "    \n",
    "    Returns:\n",
    "        image_rgb: numpy array of shape (height, width, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    # Pick latest time\n",
    "    latest_time_idx = -1\n",
    "    if data_type == 'hr':\n",
    "        # HR data: shape is (band, y, x)\n",
    "        hr_data = tree[\"hr/data\"].values\n",
    "        n_bands, height, width = hr_data.shape\n",
    "        print(f\"HR image shape: {hr_data.shape} (band, y, x)\")\n",
    "\n",
    "        # Transpose from (band, y, x) to (y, x, band) for matplotlib\n",
    "        image_rgb = np.transpose(hr_data, (1, 2, 0))\n",
    "        print(f\"Image shape after transpose: {image_rgb.shape} (y, x, band)\")\n",
    "        \n",
    "        title = \"Full HR RGB Image\"\n",
    "        \n",
    "    elif data_type == 's2':\n",
    "        # S2 data: shape is (time, y, x) for each band\n",
    "        s2_ds = tree['s2'].ds\n",
    "        \n",
    "        print(f\"S2 time dimension: {len(s2_ds.time)} timestamps\")\n",
    "        print(f\"Using latest timestamp: {s2_ds.time.values[latest_time_idx]}\")\n",
    "        \n",
    "        # Check if 'visual' band exists\n",
    "        if 'visual' in s2_ds.data_vars and not combine_rgb_bands:\n",
    "            print(\"Using pre-computed 'visual' band\")\n",
    "            s2_data = s2_ds['visual'].isel(time=latest_time_idx).values\n",
    "            \n",
    "            # If single channel, convert to RGB\n",
    "            if s2_data.ndim == 2:\n",
    "                image_rgb = np.stack([s2_data, s2_data, s2_data], axis=-1)\n",
    "            else:\n",
    "                image_rgb = s2_data\n",
    "        else:\n",
    "            # Create RGB from B04 (Red), B03 (Green), B02 (Blue)\n",
    "            print(\"Creating RGB from B04 (Red), B03 (Green), B02 (Blue)\")\n",
    "            b04 = s2_ds['B04'].isel(time=latest_time_idx).values  # Red\n",
    "            b03 = s2_ds['B03'].isel(time=latest_time_idx).values  # Green\n",
    "            b02 = s2_ds['B02'].isel(time=latest_time_idx).values  # Blue\n",
    "            \n",
    "            image_rgb = np.stack([b04, b03, b02], axis=-1)\n",
    "        \n",
    "        print(f\"S2 image shape: {image_rgb.shape} (y, x, band)\")\n",
    "        title = \"Full S2 RGB Image\"\n",
    "    \n",
    "    elif data_type == 'landsat':\n",
    "\n",
    "        landsat_ds = tree['landsat'].ds\n",
    "        print(f\"Landsat time dimension: {len(landsat_ds.time)} timestamps\")\n",
    "        print(f\"Using latest timestamp: {landsat_ds.time.values[latest_time_idx]}\")\n",
    "\n",
    "        print(\"Composing RGB from Landsat red, blue, and green bands...\")\n",
    "\n",
    "        red = landsat_ds['red'].isel(time=latest_time_idx).values\n",
    "        green = landsat_ds['green'].isel(time=latest_time_idx).values\n",
    "        blue = landsat_ds['blue'].isel(time=latest_time_idx).values\n",
    "        image_rgb = np.stack([red, green, blue], axis=-1)\n",
    "\n",
    "        print(f\"Landsat image shape: {image_rgb.shape} (y, x, band)\")\n",
    "        title = \"Full Landsat RGB Image\"\n",
    "\n",
    "        # Normalize to 0-1 range if needed\n",
    "        if image_rgb.max() > 1.0:\n",
    "            image_rgb = image_rgb / image_rgb.max()\n",
    "\n",
    "        print(f\"Image shape: {image_rgb.shape} (y, x, band)\")\n",
    "        title = \"Full Landsat RGB Image\"\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown data_type: {data_type}. Use 'hr' or 's2'.\")\n",
    "\n",
    "    # Normalize to 0-1 range if needed\n",
    "    if normalize or image_rgb.max() > 1.0:\n",
    "        image_rgb = image_rgb / image_rgb.max()\n",
    "        print(\"Normalized image to 0-1 range\")\n",
    "\n",
    "    # Display\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_full = display_full_image(tree, normalize=False)\n",
    "# display image size in MB\n",
    "print(f\"Image size: {hr_full.nbytes / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0bd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_full = display_full_image(tree, data_type='s2', combine_rgb_bands=True, normalize=False)\n",
    "print(f\"Image size: {s2_full.nbytes / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40047e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_full = display_full_image(tree, data_type='landsat')\n",
    "print(f\"Image size: {landsat_full.nbytes / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chipping_with_bboxes_header",
   "metadata": {},
   "source": [
    "## Step 6: Image Chipping with Bounding Boxes\n",
    "\n",
    "**Goal**: Create a chipping function that:\n",
    "1. Takes the full HR RGB image\n",
    "2. Chips it to a given size in pixels\n",
    "3. Uses level 19 S2 cells to draw bounding boxes\n",
    "4. Saves the list of bounding boxes for SAM prompts\n",
    "\n",
    "**Purpose**: Determine if level 19 S2 cells (~15m) are good enough for SAM box prompts,\n",
    "or if we need to use actual Polygon PV labels (which would reduce matches since many labels are Points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b201a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out our bbox in pixel coordinates on the hr_data image\n",
    "def plot_bbox_on_image(image, bbox, color='red'):\n",
    "    \"\"\"\n",
    "    Plot a bounding box on an image.\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of shape (height, width, 3)\n",
    "        bbox: tuple of (x_min, y_min, x_max, y_max) in pixel coordinates\n",
    "        color: color of the bounding box\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1], linewidth=1, edgecolor=color, facecolor='none')\n",
    "    plt.gca().add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pv_label = pv_gdf[pv_gdf['num_matches'] > 0].iloc[rand_sample_idx]\n",
    "sample_s2_cell = sample_pv_label['s2_cell_lvl_18']\n",
    "# cast to int\n",
    "sample_s2_cell = int(sample_s2_cell)\n",
    "# convert s2 cell to geo coords bbox\n",
    "sample_s2_geom = s2_cell_to_geo_bbox(sample_s2_cell)\n",
    "# get geotransform from xarray meter coords\n",
    "sample_geotransform = get_transform_from_coords(tree[\"hr\"].ds.x, tree[\"hr\"].ds.y)\n",
    "# use geotransform to convert our s2 cell bbox from lat/lon to pixel coords\n",
    "# sample_s2_bbox = s2_cell_to_bbox_pixels(sample_s2_cell, sample_geotransform)\n",
    "sample_s2_bbox = geometry_to_bbox_pixels(box(*sample_s2_geom), sample_geotransform)\n",
    "print(f\"Image shape: {hr_full.shape}\")\n",
    "print(f\"Sample S2 cell geometry: {sample_s2_geom}\")\n",
    "print(f\"GeoTransform for sample image: {sample_geotransform}\")\n",
    "print(f\"Sample S2 cell bbox: {sample_s2_bbox}\")\n",
    "plot_bbox_on_image(hr_full, sample_s2_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4813a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_pv_label.geometry.geom_type == 'Polygon':\n",
    "    sample_pv_bbox = geometry_to_bbox_pixels(sample_pv_label.geometry, sample_geotransform)\n",
    "    print(f\"Sample PV bbox: {sample_pv_bbox}\")\n",
    "    plot_bbox_on_image(hr_full, sample_pv_bbox, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21eef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bbox on hr chip\n",
    "sample_geotransform_chip = get_chip_transform(hr_meta)\n",
    "\n",
    "# Convert PV label geometry to chip pixel coordinates\n",
    "# IMPORTANT: Must pass dst_crs to transform from EPSG:4326 to image CRS!\n",
    "sample_pv_bbox_chip = geometry_to_bbox_pixels(\n",
    "    sample_pv_label.geometry, \n",
    "    sample_geotransform_chip,\n",
    "    src_crs='EPSG:4326',\n",
    "    dst_crs=hr_meta['crs']\n",
    ")\n",
    "\n",
    "# Recalculate hr_chip centered on PV label geometry\n",
    "# This ensures the PV label is in the center of the chip!\n",
    "hr_chip, hr_meta_centered = display_image_chip(\n",
    "    tree, \n",
    "    chip_size=512, \n",
    "    center_on_geometry=sample_pv_label.geometry, \n",
    "    data_type='hr'\n",
    ")\n",
    "\n",
    "# Now get the chip transform for the CENTERED chip\n",
    "sample_geotransform_chip_centered = get_chip_transform(hr_meta_centered)\n",
    "\n",
    "# Convert PV label geometry to chip pixel coordinates using the CENTERED chip's transform\n",
    "sample_pv_bbox_chip = geometry_to_bbox_pixels(\n",
    "    sample_pv_label.geometry, \n",
    "    sample_geotransform_chip_centered,\n",
    "    src_crs='EPSG:4326',\n",
    "    dst_crs=hr_meta_centered['crs']\n",
    ")\n",
    "\n",
    "# Also convert S2 cell bbox\n",
    "sample_s2_bbox_chip = s2_cell_to_bbox_pixels(\n",
    "    sample_s2_cell,\n",
    "    sample_geotransform_chip_centered,\n",
    "    dst_crs=hr_meta_centered['crs']\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Chip Info ===\")\n",
    "print(f\"Chip centered on PV label: {sample_pv_label.geometry.centroid}\")\n",
    "print(f\"Chip position in full image: y={hr_meta_centered['y_start']}, x={hr_meta_centered['x_start']}\")\n",
    "print(f\"Chip CRS: {hr_meta_centered['crs']}\")\n",
    "print(f\"Chip shape: {hr_chip.shape}\")\n",
    "print(f\"\\n=== Bbox Coordinates (in chip pixels) ===\")\n",
    "print(f\"PV label bbox: {sample_pv_bbox_chip}\")\n",
    "print(f\"S2 cell bbox: {sample_s2_bbox_chip}\")\n",
    "\n",
    "# Plot bbox on chip\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(hr_chip)\n",
    "\n",
    "# Plot PV label bbox (red)\n",
    "x_min, y_min, x_max, y_max = sample_pv_bbox_chip\n",
    "rect = Rectangle(\n",
    "    (x_min, y_min), \n",
    "    x_max - x_min, \n",
    "    y_max - y_min,\n",
    "    linewidth=2, \n",
    "    edgecolor='red', \n",
    "    facecolor='none',\n",
    "    label='PV Label'\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# Plot S2 cell bbox (green) for comparison\n",
    "x_min, y_min, x_max, y_max = sample_s2_bbox_chip\n",
    "rect = Rectangle(\n",
    "    (x_min, y_min),\n",
    "    x_max - x_min,\n",
    "    y_max - y_min,\n",
    "    linewidth=2,\n",
    "    edgecolor='green',\n",
    "    facecolor='none',\n",
    "    label='S2 Cell (lvl 18)'\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(f'HR Chip with Bboxes (Centered on PV Label)\\nCRS: {hr_meta_centered[\"crs\"]}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bbox on s2 full image\n",
    "sample_geotransform_s2 = get_transform_from_coords(tree[\"s2\"].ds.x, tree[\"s2\"].ds.y)\n",
    "sample_s2_bbox = geometry_to_bbox_pixels(box(*sample_s2_geom), sample_geotransform_s2)\n",
    "print(f\"Sample S2 cell bbox (S2): {sample_s2_bbox}\")\n",
    "plot_bbox_on_image(s2_full, sample_s2_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sam_integration_header",
   "metadata": {},
   "source": [
    "## Step 7: SAM Integration\n",
    "\n",
    "**Goal**: Test SAM segmentation with our matched PV labels and imagery.\n",
    "\n",
    "**References**:\n",
    "- [Box prompts](https://samgeo.gishub.org/examples/box_prompts/)\n",
    "- [SAM2 box prompts](https://samgeo.gishub.org/examples/sam2_box_prompts/)\n",
    "- [Text prompts](https://samgeo.gishub.org/examples/text_prompts/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sam2_box_prompts_header",
   "metadata": {},
   "source": [
    "### 7A: SAM2 with Box Prompts (Recommended)\n",
    "\n",
    "Using level 19 S2 cells or PV polygon geometries as box prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4cd8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# SAM2 with Box Prompts - Using our matched data\n",
    "from samgeo import SamGeo2\n",
    "from samgeo.common import raster_to_vector, regularize\n",
    "import numpy as np\n",
    "\n",
    "# Sample a random PV label with matches\n",
    "matched_pv = pv_gdf[pv_gdf['num_matches'] > 0]\n",
    "sample_idx = np.random.randint(0, len(matched_pv))\n",
    "sample_label = matched_pv.iloc[sample_idx]\n",
    "\n",
    "print(f\"Sampled PV label {sample_idx}:\")\n",
    "print(f\"  Geometry type: {sample_label.geometry.geom_type}\")\n",
    "print(f\"  Matched files: {sample_label['num_matches']}\")\n",
    "print(f\"  S2 cell token (lvl {S2_CELL_LVL}): {s2cell.cell_id_to_token(int(sample_label[f's2_cell_lvl_{S2_CELL_LVL}']))}\")\n",
    "\n",
    "# Load the matched image\n",
    "sample_file = sample_label['matched_files'][0]\n",
    "filename = \"/\".join(Path(sample_file).parts[3:])\n",
    "url = f\"https://huggingface.co/datasets/gajeshladhar/core-five/resolve/main/{filename}\"\n",
    "\n",
    "print(f\"\\nLoading image: {filename}\")\n",
    "\n",
    "# Load image with fsspec\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "\n",
    "with fsspec.open(url, 'rb') as f:\n",
    "    tree = xr.open_datatree(f, engine='h5netcdf')\n",
    "    tree.load()\n",
    "\n",
    "# Extract HR RGB chip centered on the PV label geometry\n",
    "print(f\"\\n=== Extracting Image Chip ===\")\n",
    "hr_chip, hr_meta = display_image_chip(\n",
    "    tree,\n",
    "    chip_size=512,  # 512x512 chip\n",
    "    data_type='hr',\n",
    "    center_on_geometry=sample_label.geometry  # Center on PV geometry\n",
    ")\n",
    "\n",
    "print(f\"Chip shape: {hr_chip.shape}\")\n",
    "print(f\"Chip dtype: {hr_chip.dtype}\")\n",
    "print(f\"Chip value range: [{hr_chip.min()}, {hr_chip.max()}]\")\n",
    "print(f\"Chip CRS: {hr_meta['crs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_chip_bbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the chip with bbox overlay to verify quality\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Get chip geotransform\n",
    "chip_geotransform = get_chip_transform(hr_meta)\n",
    "\n",
    "# Convert PV label geometry to chip pixel coordinates\n",
    "pv_bbox_chip = geometry_to_bbox_pixels(\n",
    "    sample_label.geometry,\n",
    "    chip_geotransform,\n",
    "    src_crs='EPSG:4326',\n",
    "    dst_crs=hr_meta['crs']\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Bbox Coordinates (in chip pixels) ===\")\n",
    "print(f\"PV label bbox: {pv_bbox_chip}\")\n",
    "\n",
    "# Plot bbox on chip\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(hr_chip)\n",
    "\n",
    "# Plot PV label bbox (red)\n",
    "x_min, y_min, x_max, y_max = pv_bbox_chip\n",
    "rect = Rectangle(\n",
    "    (x_min, y_min),\n",
    "    x_max - x_min,\n",
    "    y_max - y_min,\n",
    "    linewidth=2,\n",
    "    edgecolor='red',\n",
    "    facecolor='none',\n",
    "    label='PV Label Bbox'\n",
    ")\n",
    "ax.add_patch(rect)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(f'HR Chip with Bbox (Centered on PV Label)\\nCRS: {hr_meta[\"crs\"]}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sam2_box_prompts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bounding boxes from geometry\n",
    "# Option 1: Use PV geometry directly (if Polygon)\n",
    "# Option 2: Use level 19 S2 cell\n",
    "import rasterio\n",
    "\n",
    "if sample_label.geometry.geom_type == 'Polygon':\n",
    "    # Use actual PV polygon bounds\n",
    "    bounds = sample_label.geometry.bounds  # (minx, miny, maxx, maxy)\n",
    "    boxes = [[bounds[0], bounds[1], bounds[2], bounds[3]]]  # [left, bottom, right, top]\n",
    "    print(f\"\\nUsing Polygon geometry as box prompt\")\n",
    "else:\n",
    "    # Use S2 cell or buffer Point geometry\n",
    "    # For now, use S2 cell bounds (approximate)\n",
    "    centroid = sample_label['centroid']\n",
    "    cell_size_deg = 0.0002  # ~15m at equator\n",
    "    boxes = [[\n",
    "        centroid.x - cell_size_deg/2,\n",
    "        centroid.y - cell_size_deg/2,\n",
    "        centroid.x + cell_size_deg/2,\n",
    "        centroid.y + cell_size_deg/2\n",
    "    ]]\n",
    "    print(f\"\\nUsing S2 cell (level 19) as box prompt\")\n",
    "\n",
    "print(f\"Box prompt (lat/lon): {boxes}\")\n",
    "\n",
    "# Save chip as GeoTIFF with proper geospatial metadata\n",
    "# This is required for SAM2's point_crs parameter to work\n",
    "temp_image_path = \"../data/temp_sam_input.tif\"\n",
    "save_chip_as_geotiff(hr_chip, hr_meta, temp_image_path)\n",
    "\n",
    "print(f\"\\nSaved chip as GeoTIFF to: {temp_image_path}\")\n",
    "print(f\"  CRS: {hr_meta['crs']}\")\n",
    "print(f\"  Chip bounds: ({hr_meta['x_coords'].min()}, {hr_meta['y_coords'].min()}, \"\n",
    "      f\"{hr_meta['x_coords'].max()}, {hr_meta['y_coords'].max()})\")\n",
    "\n",
    "# Initialize SAM2\n",
    "print(f\"\\nInitializing SAM2...\")\n",
    "sam = SamGeo2(\n",
    "    model_id=\"sam2-hiera-small\",\n",
    "    automatic=False,\n",
    "    device=\"cpu\"  # Use \"cuda\" for GPU, \"cpu\" for CPU\n",
    "    # Note: MPS (Apple Silicon) not supported due to float64 limitation\n",
    ")\n",
    "\n",
    "# Set image from GeoTIFF (this properly sets sam.image and sam.source)\n",
    "sam.set_image(temp_image_path)\n",
    "print(f\"Image set successfully\")\n",
    "print(f\"  Image shape: {sam.image.shape}\")\n",
    "print(f\"  Image dtype: {sam.image.dtype}\")\n",
    "\n",
    "# Predict with box prompts (boxes are in EPSG:4326, SAM2 will transform to image CRS)\n",
    "print(f\"\\nRunning SAM2 prediction...\")\n",
    "\n",
    "# Don't pass output= to avoid tensor_to_numpy bug with single boxes\n",
    "masks, scores, logits = sam.predict(\n",
    "    boxes=boxes,  # Boxes in EPSG:4326 (lat/lon)\n",
    "    point_crs=\"EPSG:4326\",  # SAM2 will transform from EPSG:4326 to image CRS\n",
    "    multimask_output=False,\n",
    "    return_results=True\n",
    ")\n",
    "\n",
    "print(f\"Prediction complete!\")\n",
    "print(f\"  Masks shape: {masks.shape}\")\n",
    "print(f\"  Scores: {scores}\")\n",
    "\n",
    "# Save mask manually using rasterio (with geospatial metadata from input)\n",
    "output_path = \"../data/sam2_box_mask.tif\"\n",
    "\n",
    "# Get the mask (for single box with multimask_output=False, shape is (1, H, W))\n",
    "mask = masks[0]  # Get first (and only) mask\n",
    "\n",
    "# Save with same geospatial metadata as input\n",
    "with rasterio.open(temp_image_path) as src:\n",
    "    profile = src.profile.copy()\n",
    "    profile.update(\n",
    "        count=1,\n",
    "        dtype='uint8',\n",
    "        compress='deflate'\n",
    "    )\n",
    "\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write((mask * 255).astype('uint8'), 1)\n",
    "\n",
    "print(f\" Mask saved to: {output_path}\")\n",
    "\n",
    "# Convert to vector\n",
    "vector_path = \"../data/sam2_box_vector.geojson\"\n",
    "raster_to_vector(output_path, vector_path)\n",
    "print(f\" Vector saved to: {vector_path}\")\n",
    "\n",
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "\n",
    "# Load the mask from file\n",
    "with rasterio.open(output_path) as src:\n",
    "    mask = src.read(1)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(hr_chip)  # Use the chipped image, not the full image\n",
    "plt.imshow(mask, alpha=0.5, cmap='Reds')\n",
    "plt.title(f'SAM2 Box Prompt Result\\nChip size: {hr_chip.shape[0]}x{hr_chip.shape[1]}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sam_text_prompts_header",
   "metadata": {},
   "source": [
    "### 7B: LangSAM with Text Prompts\n",
    "\n",
    "Using text prompt \"solar panel\" to detect PV installations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sam_text_prompts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSAM with Text Prompts - Using our matched data\n",
    "from samgeo.text_sam import LangSAM\n",
    "\n",
    "# Use the same sampled image from above\n",
    "print(f\"Using same image: {filename}\")\n",
    "print(f\"Image shape: {hr_chip.shape}\")\n",
    "\n",
    "# Initialize LangSAM\n",
    "print(f\"\\nInitializing LangSAM...\")\n",
    "sam_text = LangSAM()\n",
    "\n",
    "# Text prompt\n",
    "text_prompt = \"solar panel\"\n",
    "print(f\"Text prompt: '{text_prompt}'\")\n",
    "\n",
    "# Predict\n",
    "output_path_text = \"../data/langsam_text_mask.tif\"\n",
    "print(f\"\\nRunning LangSAM prediction...\")\n",
    "\n",
    "sam_text.predict(\n",
    "    hr_chip,\n",
    "    text_prompt,\n",
    "    box_threshold=0.24,  # Object detection confidence\n",
    "    text_threshold=0.24,  # Text-object association confidence\n",
    "    output=output_path_text\n",
    ")\n",
    "\n",
    "print(f\" Mask saved to: {output_path_text}\")\n",
    "\n",
    "# Convert to vector\n",
    "vector_path_text = \"../data/langsam_text_vector.geojson\"\n",
    "sam_text.raster_to_vector(output_path_text, vector_path_text)\n",
    "print(f\" Vector saved to: {vector_path_text}\")\n",
    "\n",
    "# Visualize\n",
    "sam_text.show_anns(cmap=\"Greens\", box_color=\"red\", blend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sam_original_header",
   "metadata": {},
   "source": [
    "### 7C: Original SAM with Box Prompts\n",
    "\n",
    "Using the original Segment Anything Model (SAM) with box prompts from PV polygon bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sam_original_box",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original SAM with Box Prompts\n",
    "from samgeo import SamGeo\n",
    "\n",
    "print(f\"\\n=== Original SAM with Box Prompts ===\")\n",
    "print(f\"Using same image from Step 7A\")\n",
    "print(f\"Image shape: {hr_rgb.shape}\")\n",
    "print(f\"Image dtype: {hr_rgb.dtype}\")\n",
    "\n",
    "# Initialize original SAM\n",
    "print(f\"\\nInitializing SAM (vit_h)...\")\n",
    "sam_orig = SamGeo(\n",
    "    model_type=\"vit_h\",  # Options: vit_h, vit_l, vit_b\n",
    "    automatic=False,\n",
    "    sam_kwargs=None,\n",
    ")\n",
    "\n",
    "# Set image\n",
    "sam_orig.set_image(hr_rgb)\n",
    "print(f\"Image set successfully\")\n",
    "\n",
    "# Use the same box prompts from 7A (in lat/lon)\n",
    "print(f\"\\nBox prompts (lat/lon): {boxes}\")\n",
    "\n",
    "# Predict with box prompts\n",
    "output_path_orig = \"../data/sam_original_box_mask.tif\"\n",
    "print(f\"\\nRunning SAM prediction...\")\n",
    "\n",
    "sam_orig.predict(\n",
    "    boxes=boxes,\n",
    "    point_crs=\"EPSG:4326\",  # Original SAM handles CRS conversion properly\n",
    "    output=output_path_orig,\n",
    "    dtype=\"uint8\",\n",
    "    multimask_output=False\n",
    ")\n",
    "\n",
    "print(f\" Mask saved to: {output_path_orig}\")\n",
    "\n",
    "# Convert to vector\n",
    "vector_path_orig = \"../data/sam_original_box_vector.geojson\"\n",
    "sam_orig.raster_to_vector(output_path_orig, vector_path_orig)\n",
    "print(f\" Vector saved to: {vector_path_orig}\")\n",
    "\n",
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(hr_rgb)\n",
    "if hasattr(sam_orig, 'prediction') and sam_orig.prediction is not None:\n",
    "    plt.imshow(sam_orig.prediction, alpha=0.5, cmap='Oranges')\n",
    "plt.title('Original SAM Box Prompt Result')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sam_hq_header",
   "metadata": {},
   "source": [
    "### 7D: SAM-HQ with Point Prompts\n",
    "\n",
    "Using SAM-HQ (High Quality) with point prompts at PV label centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sam_hq_point",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM-HQ with Point Prompts\n",
    "from samgeo.hq_sam import SamGeo as SamGeoHQ\n",
    "\n",
    "print(f\"\\n=== SAM-HQ with Point Prompts ===\")\n",
    "print(f\"Using same image from Step 7A\")\n",
    "print(f\"Image shape: {hr_rgb.shape}\")\n",
    "print(f\"Image dtype: {hr_rgb.dtype}\")\n",
    "\n",
    "# Initialize SAM-HQ\n",
    "print(f\"\\nInitializing SAM-HQ (vit_h)...\")\n",
    "sam_hq = SamGeoHQ(\n",
    "    model_type=\"vit_h\",  # Options: vit_h, vit_l, vit_b, vit_tiny\n",
    "    automatic=False,\n",
    "    sam_kwargs=None,\n",
    ")\n",
    "\n",
    "# Set image\n",
    "sam_hq.set_image(hr_rgb)\n",
    "print(f\"Image set successfully\")\n",
    "\n",
    "# Use centroid from the matched label as point prompt\n",
    "point_coords = [[sample_label['centroid_lon'], sample_label['centroid_lat']]]\n",
    "point_labels = [1]  # 1 = foreground point\n",
    "\n",
    "print(f\"\\nPoint prompts (lat/lon): {point_coords}\")\n",
    "print(f\"Point labels: {point_labels} (1=foreground)\")\n",
    "\n",
    "# Predict with point prompts\n",
    "output_path_hq = \"../data/sam_hq_point_mask.tif\"\n",
    "print(f\"\\nRunning SAM-HQ prediction...\")\n",
    "\n",
    "sam_hq.predict(\n",
    "    point_coords=point_coords,\n",
    "    point_labels=point_labels,\n",
    "    point_crs=\"EPSG:4326\",  # SAM-HQ handles CRS conversion\n",
    "    output=output_path_hq,\n",
    "    dtype=\"uint8\",\n",
    "    multimask_output=False\n",
    ")\n",
    "\n",
    "print(f\" Mask saved to: {output_path_hq}\")\n",
    "\n",
    "# Convert to vector\n",
    "vector_path_hq = \"../data/sam_hq_point_vector.geojson\"\n",
    "sam_hq.raster_to_vector(output_path_hq, vector_path_hq)\n",
    "print(f\" Vector saved to: {vector_path_hq}\")\n",
    "\n",
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(hr_rgb)\n",
    "if hasattr(sam_hq, 'prediction') and sam_hq.prediction is not None:\n",
    "    plt.imshow(sam_hq.prediction, alpha=0.5, cmap='Purples')\n",
    "# Mark the centroid point\n",
    "from shapely.geometry import Point\n",
    "centroid = Point(sample_label['centroid_lon'], sample_label['centroid_lat'])\n",
    "# Convert to pixel coords for plotting\n",
    "transform = get_transform_from_coords(tree[\"hr\"].ds.x, tree[\"hr\"].ds.y)\n",
    "px, py = geo_to_pixel_coords(centroid.x, centroid.y, transform, 'EPSG:4326', tree.attrs.get('crs'))\n",
    "plt.scatter(px, py, c='red', s=100, marker='*', edgecolors='white', linewidths=1.5, label='Centroid Point')\n",
    "plt.title('SAM-HQ Point Prompt Result')\n",
    "plt.legend()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737f79b",
   "metadata": {},
   "source": [
    "## VirtualiZarr [Future Work for processing multiple files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696149a9",
   "metadata": {},
   "source": [
    "#### OPTION 2A: VirtualiZarr with HTTP Store + Authentication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step5_virtualizarr_in_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Based on:\n",
    "#   - VirtualiZarr docs: https://virtualizarr.readthedocs.io/en/stable/usage.html\n",
    "#   - obstore ClientConfig: https://developmentseed.org/obstore/latest/api/store/config/\n",
    "# Using HTTPStore with client_options={'default_headers': {'Authorization': 'Bearer ...'}}\n",
    "\n",
    "from virtualizarr import open_virtual_dataset\n",
    "from virtualizarr.parsers import HDFParser\n",
    "from virtualizarr.registry import ObjectStoreRegistry\n",
    "from obstore.store import HTTPStore\n",
    "\n",
    "# Get HuggingFace token from environment\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "\n",
    "if not hf_token:\n",
    "    print(\"WARNING: HF_TOKEN not found in environment.\")\n",
    "    print(\"VirtualiZarr may fail with 401 Unauthorized for private datasets.\")\n",
    "    print(\"Set HF_TOKEN in your .env file for authenticated access.\")\n",
    "else:\n",
    "    print(\" HF_TOKEN found - using authenticated access\")\n",
    "\n",
    "if (pv_gdf['num_matches'] > 0).sum() > 0:\n",
    "    sample_file = pv_gdf[pv_gdf['num_matches'] > 0].iloc[rand_sample_idx]['matched_files'][0]\n",
    "    filename = \"/\".join(Path(sample_file).parts[3:])\n",
    "    url = f\"https://huggingface.co/datasets/gajeshladhar/core-five/resolve/main/{filename}\"\n",
    "    \n",
    "    print(f\"\\nVirtualizing file: {filename}\")\n",
    "    print(f\"URL: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # Create HTTP store with authentication\n",
    "        # ClientConfig.default_headers accepts dict[str, str] | dict[str, bytes]\n",
    "        bucket = \"https://huggingface.co\"\n",
    "        \n",
    "        # Create HTTPStore with authentication headers via client_options\n",
    "        if hf_token:\n",
    "            # HTTPStore with Bearer token authentication\n",
    "            # This is the CORRECT way per obstore docs\n",
    "            store = HTTPStore.from_url(\n",
    "                bucket,\n",
    "                client_options={\n",
    "                    'default_headers': {\n",
    "                        'Authorization': f'Bearer {hf_token}'\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            # HTTPStore without authentication (for public datasets)\n",
    "            store = HTTPStore.from_url(bucket)\n",
    "        \n",
    "        registry = ObjectStoreRegistry({bucket: store})\n",
    "        \n",
    "        # Open as virtual dataset\n",
    "        print(\"Creating virtual dataset...\")\n",
    "        vds = open_virtual_dataset(\n",
    "            url=url,\n",
    "            registry=registry,\n",
    "            parser=HDFParser(),\n",
    "            loadable_variables=['time', 'x', 'y'],  # Load coords, virtualize data\n",
    "            decode_times=True  # Decode CF time variables\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n Virtual dataset created!\")\n",
    "        print(f\"  Variables: {list(vds.data_vars)}\")\n",
    "        print(f\"  Coordinates: {list(vds.coords)}\")\n",
    "        print(f\"  Dimensions: {dict(vds.dims)}\")\n",
    "        print(f\"\\nMemory footprint (virtual refs only): {vds.vz.nbytes / 1024**2:.2f} MB\")\n",
    "        print(f\"Actual data size (if loaded): {vds.nbytes / 1024**2:.2f} MB\")\n",
    "        \n",
    "        # Show what's virtual vs loaded\n",
    "        print(f\"\\nData variables (virtualized):\")\n",
    "        for var in vds.data_vars:\n",
    "            print(f\"  - {var}: {vds[var].shape}\")\n",
    "        \n",
    "        print(f\"\\nCoordinates (loaded into memory):\")\n",
    "        for coord in vds.coords:\n",
    "            print(f\"  - {coord}: {vds[coord].shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "        print(f\"\\nTroubleshooting:\")\n",
    "        print(f\"1. Check if HF_TOKEN is set correctly in .env\")\n",
    "        print(f\"2. Verify token has access to gajeshladhar/core-five dataset\")\n",
    "        print(f\"3. Try accessing URL directly in browser to test authentication\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"No matches found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtualizarr_mfdataset_header",
   "metadata": {},
   "source": [
    "#### OPTION 2B: VirtualiZarr - Multiple Files (COMMENTED OUT - For Future E2E Pipelines)\n",
    "\n",
    "**Note**: This approach is premature for the current notebook's depth-first workflow.\n",
    "\n",
    "**Issue**: Fails with `ValueError: Could not find any dimension coordinates` due to:\n",
    "- Different coordinate orders between `/hr` and `/s2` groups\n",
    "- `spatial_ref` being a data variable instead of coordinate in `/s2`\n",
    "\n",
    "**Future Use**: Ideal for E2E pipelines:\n",
    "- Virtualize datasets  store as Icechunk/Kerchunk parquet in R2\n",
    "- Materialize images at runtime with Lance or in-memory format\n",
    "\n",
    "**Commented out for now** - see OPTION 2C below for single-group virtualization approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtualizarr_mfdataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENTED OUT - See markdown above for reasoning\n",
    "# Uncomment for future E2E pipeline work\n",
    "\n",
    "# from virtualizarr import open_virtual_mfdataset\n",
    "# from virtualizarr.parsers import HDFParser\n",
    "# from virtualizarr.registry import ObjectStoreRegistry\n",
    "# from obstore.store import HTTPStore\n",
    "\n",
    "# # Get HuggingFace token from environment\n",
    "# hf_token = os.getenv('HF_TOKEN')\n",
    "# \n",
    "# if not hf_token:\n",
    "#     print(\"WARNING: HF_TOKEN not found in environment.\")\n",
    "#     print(\"Set HF_TOKEN in your .env file for authenticated access.\")\n",
    "# else:\n",
    "#     print(\" HF_TOKEN found - using authenticated access\")\n",
    "# \n",
    "# # ... rest of code commented out ...\n",
    "# # See git history or uncomment for future E2E pipeline work\n",
    "\n",
    "pass  # Placeholder to keep cell valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtualizarr_single_group_header",
   "metadata": {},
   "source": [
    "#### OPTION 2C: VirtualiZarr - Single DataTree Group (Experimental)\n",
    "\n",
    "**Exploring**: Can we virtualize individual groups from a DataTree?\n",
    "\n",
    "**Approach**: Extract a single group (e.g., `/hr` or `/s2`) as an xarray Dataset, then virtualize it.\n",
    "\n",
    "**Goal**: Get a manageable \"feel\" for loading and saving virtual datasets before scaling up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtualizarr_single_group",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2C: Virtualize a single DataTree group\n",
    "# Test: Can we use VirtualiZarr to virtualize a specific group from the NetCDF file?\n",
    "# Approach: Use open_virtual_dataset with group parameter (if supported)\n",
    "\n",
    "import xarray as xr\n",
    "from virtualizarr import open_virtual_dataset\n",
    "from virtualizarr.parsers import HDFParser\n",
    "from virtualizarr.registry import ObjectStoreRegistry\n",
    "from obstore.store import HTTPStore\n",
    "\n",
    "# Get HuggingFace token\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "\n",
    "if not hf_token:\n",
    "    print(\"WARNING: HF_TOKEN not found\")\n",
    "else:\n",
    "    print(\" HF_TOKEN found\")\n",
    "\n",
    "if (pv_gdf['num_matches'] > 0).sum() > 0:\n",
    "    sample_file = pv_gdf[pv_gdf['num_matches'] > 0].iloc[rand_sample_idx]['matched_files'][0]\n",
    "    filename = \"/\".join(Path(sample_file).parts[3:])\n",
    "    url = f\"https://huggingface.co/datasets/gajeshladhar/core-five/resolve/main/{filename}\"\n",
    "    \n",
    "    print(f\"\\nFile: {filename}\")\n",
    "    print(f\"URL: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # Create HTTP store with authentication\n",
    "        bucket = \"https://huggingface.co\"\n",
    "        \n",
    "        if hf_token:\n",
    "            store = HTTPStore.from_url(\n",
    "                bucket,\n",
    "                client_options={\n",
    "                    'default_headers': {\n",
    "                        'Authorization': f'Bearer {hf_token}'\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            store = HTTPStore.from_url(bucket)\n",
    "        \n",
    "        registry = ObjectStoreRegistry({bucket: store})\n",
    "        \n",
    "        # Test 1: Can we virtualize a specific HDF5 group?\n",
    "        # NetCDF4 files are HDF5 files with groups like /hr/data and /s2\n",
    "        print(f\"\\n--- Test 1: Virtualizing /hr/data group ---\")\n",
    "        \n",
    "        # HDFParser might support group parameter\n",
    "        # Let's try passing group to the parser\n",
    "        try:\n",
    "            vds_hr = open_virtual_dataset(\n",
    "                url=url,\n",
    "                registry=registry,\n",
    "                parser=HDFParser(group='/hr/data'),  # Try specifying group\n",
    "                loadable_variables=['x', 'y', 'band'],\n",
    "                decode_times=False\n",
    "            )\n",
    "            \n",
    "            print(f\" Virtualized /hr/data group!\")\n",
    "            print(f\"  Variables: {list(vds_hr.data_vars)}\")\n",
    "            print(f\"  Coordinates: {list(vds_hr.coords)}\")\n",
    "            print(f\"  Dimensions: {dict(vds_hr.dims)}\")\n",
    "            print(f\"  Virtual size: {vds_hr.vz.nbytes / 1024**2:.2f} MB\")\n",
    "            print(f\"  Actual size: {vds_hr.nbytes / 1024**2:.2f} MB\")\n",
    "            \n",
    "        except TypeError as e:\n",
    "            if 'group' in str(e):\n",
    "                print(f\" HDFParser doesn't support 'group' parameter\")\n",
    "                print(f\"  Error: {e}\")\n",
    "                \n",
    "                # Test 2: Virtualize the whole file, then extract group\n",
    "                print(f\"\\n--- Test 2: Virtualize whole file, extract group later ---\")\n",
    "                \n",
    "                vds_full = open_virtual_dataset(\n",
    "                    url=url,\n",
    "                    registry=registry,\n",
    "                    parser=HDFParser(),\n",
    "                    loadable_variables=['x', 'y', 'time'],\n",
    "                    decode_times=True\n",
    "                )\n",
    "                \n",
    "                print(f\" Virtualized full file\")\n",
    "                print(f\"  Variables: {list(vds_full.data_vars)}\")\n",
    "                print(f\"  Coordinates: {list(vds_full.coords)}\")\n",
    "                \n",
    "                # Check if we can access groups from the virtual dataset\n",
    "                print(f\"\\n  Note: VirtualiZarr returns a flat xarray.Dataset\")\n",
    "                print(f\"  It doesn't preserve HDF5 group hierarchy\")\n",
    "                print(f\"  All variables from all groups are flattened into one Dataset\")\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        # Conclusion\n",
    "        print(f\"\\n--- Conclusion ---\")\n",
    "        print(f\"VirtualiZarr flattens HDF5 groups into a single xarray.Dataset\")\n",
    "        print(f\"For our workflow (single group at a time), direct xarray loading is simpler\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")\n",
    "        \n",
    "        # Known issue: HDFParser doesn't support group parameter\n",
    "        if \"is not an HDF Group\" in str(e):\n",
    "            print(f\"\\n Confirmed: HDFParser doesn't support reading specific HDF5 groups\")\n",
    "            print(f\"  VirtualiZarr flattens all groups into a single Dataset\")\n",
    "            print(f\"  For our workflow (one group at a time), direct xarray loading is better\")\n",
    "        else:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "else:\n",
    "    print(\"No matches found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtualizarr_conclusion",
   "metadata": {},
   "source": [
    "#### VirtualiZarr Findings\n",
    "\n",
    "**What we tested**:\n",
    "1.  **Single file virtualization** (OPTION 2A) - Works with authentication\n",
    "2.  **Multiple file virtualization** (OPTION 2B) - Coordinate mismatch between groups\n",
    "3.  **Single group virtualization** (OPTION 2C) - Testing if HDFParser supports group parameter\n",
    "\n",
    "**Key findings**:\n",
    "- VirtualiZarr **flattens HDF5 groups** into a single xarray.Dataset\n",
    "- Doesn't preserve DataTree hierarchy (all groups merged)\n",
    "- For working with **one group at a time** (our workflow), direct xarray loading is simpler\n",
    "\n",
    "**For this notebook's depth-first workflow**:\n",
    "-  **Direct xarray loading** is the right approach\n",
    "-  Loads individual DataTree groups on-demand\n",
    "-  Simple, straightforward, works perfectly for SAM segmentation\n",
    "\n",
    "**VirtualiZarr is better suited for**:\n",
    "-  E2E pipelines virtualizing thousands of files\n",
    "-  Storing references in Icechunk/Kerchunk for repeated access\n",
    "-  Materializing data at runtime from virtual stores\n",
    "-  When you need to work with the **entire file** (all groups), not individual groups\n",
    "\n",
    "**Next**: Continue with image display and SAM segmentation workflow using direct xarray loading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aegir-Eiders-Lightning-Lance (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
